{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T05:57:50.126944Z",
     "start_time": "2018-12-12T05:57:50.101031Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参考https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-09-RNN3/\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T07:28:12.766940Z",
     "start_time": "2018-12-12T07:28:11.694650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "波士顿数据X: (506,)\n",
      "波士顿房价Y: (506,)\n"
     ]
    }
   ],
   "source": [
    "#单值定义\n",
    "%matplotlib qt\n",
    "tf.reset_default_graph()\n",
    "# 波士顿房价数据\n",
    "boston = load_boston()\n",
    "x = boston.target\n",
    "y = boston.target\n",
    "\n",
    "print('波士顿数据X:', x.shape)  # (506, 1)\n",
    "# print(x[::100])\n",
    "print('波士顿房价Y:', y.shape)\n",
    "# print(y[::100])\n",
    "# 数据标准化\n",
    "ss_x = preprocessing.StandardScaler()\n",
    "train_x = ss_x.fit_transform(y.reshape(-1, 1))\n",
    "ss_y = preprocessing.StandardScaler()\n",
    "train_y = ss_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "BATCH_START = 0  # 建立 batch data 时候的 index\n",
    "TIME_STEPS = 10  # backpropagation through time 的 time_steps\n",
    "BATCH_SIZE = 30\n",
    "INPUT_SIZE = 1  \n",
    "OUTPUT_SIZE = 1  \n",
    "CELL_SIZE = 10  # RNN 的 hidden unit size\n",
    "LR = 0.006  # learning rate\n",
    "# 保存session状态的位置\n",
    "save_dir = './bst_save/ckpt/bst'\n",
    "# logs_path = './bst_save/log/'\n",
    "\n",
    "# def get_batch_boston_10():\n",
    "#     global train_x_list, train_y_list, BATCH_START, TIME_STEPS\n",
    "#     train_x_list,train_y_list=[],[]\n",
    "#     #(291, 10, 1)\n",
    "#     for i in range(len(train_y)-TIME_STEPS-205):\n",
    "#         x1=train_y[i:i+TIME_STEPS]\n",
    "#         y1=train_y[i+1:i+TIME_STEPS+1]\n",
    "#     #     x1=x1.reshape(30,10,-1)\n",
    "#     #     y1=x1.reshape(30,10,-1)\n",
    "#         train_x_list.append(x1.tolist())\n",
    "#         train_y_list.append(y1.tolist()) \n",
    "#     train_x_np = np.array(train_x_list)\n",
    "#     train_y_np = np.array(train_y_list)\n",
    "\n",
    "#     seq = train_x_np\n",
    "#     res = train_y_np\n",
    "#     return [seq, res]\n",
    "\n",
    "\n",
    "# def get_batch_boston_original():\n",
    "#     global train_x, train_y, BATCH_START, TIME_STEPS\n",
    "#     # 每次都是拿300行，13列的数据，但是起始点根据 BATCH_START\n",
    "#     x_part1 = train_x[BATCH_START:BATCH_START + TIME_STEPS * BATCH_SIZE]\n",
    "#     y_part1 = train_y[BATCH_START:BATCH_START + TIME_STEPS * BATCH_SIZE]\n",
    "#     # 时间段= 0 300\n",
    "#     # x_part1= (300, 13)\n",
    "#     # 时间段= 10 310\n",
    "#     # x_part1= (300, 13)\n",
    "# #     print('时间段=', BATCH_START, BATCH_START + TIME_STEPS * BATCH_SIZE)\n",
    "# #     print('x_part1=', x_part1.shape)\n",
    "# #     print(BATCH_SIZE, TIME_STEPS, INPUT_SIZE)\n",
    "#     # 转成 30 10 13的形状\n",
    "#     seq = x_part1.reshape((BATCH_SIZE, TIME_STEPS, INPUT_SIZE))\n",
    "#     res = y_part1.reshape((BATCH_SIZE, TIME_STEPS, 1))\n",
    "\n",
    "#     BATCH_START += TIME_STEPS\n",
    "\n",
    "#     # returned seq, res and xs: shape (batch, step, input)\n",
    "#     #np.newaxis 用来增加一个维度 变为三个维度，第三个维度将用来存上一批样本的状态\n",
    "#     return [seq, res]\n",
    "\n",
    "#300\n",
    "def get_batch_boston():\n",
    "    global train_x_list, train_y_list, BATCH_START, TIME_STEPS\n",
    "    train_x_list,train_y_list=[],[]\n",
    "    for i in range(20):\n",
    "        x1=train_y[i:i+TIME_STEPS*BATCH_SIZE]\n",
    "        y1=train_y[i+1:i+TIME_STEPS*BATCH_SIZE+1]\n",
    "#         y1=train_y[i:i+TIME_STEPS*BATCH_SIZE]\n",
    "        x1=x1.reshape(30,10,-1)\n",
    "        y1=y1.reshape(30,10,-1)\n",
    "        train_x_list.append(x1.tolist())\n",
    "        train_y_list.append(y1.tolist()) \n",
    "    train_x_np = np.array(train_x_list)\n",
    "    train_y_np = np.array(train_y_list)\n",
    "\n",
    "    seq = train_x_np\n",
    "    res = train_y_np\n",
    "    return [seq, res]\n",
    "\n",
    "\n",
    "\n",
    "# def get_batch():\n",
    "#     global BATCH_START, TIME_STEPS\n",
    "#     # xs shape (50batch, 20steps)\n",
    "#     xs = np.arange(BATCH_START, BATCH_START + TIME_STEPS * BATCH_SIZE).reshape(\n",
    "#         (BATCH_SIZE, TIME_STEPS)) / (10 * np.pi)\n",
    "#     print('xs.shape=', xs.shape)\n",
    "#     seq = np.sin(xs)\n",
    "#     res = np.cos(xs)\n",
    "#     BATCH_START += TIME_STEPS\n",
    "#     # import matplotlib.pyplot as plt\n",
    "#     # plt.plot(xs[0, :], res[0, :], 'r', xs[0, :], seq[0, :], 'b--')\n",
    "#     # plt.show()\n",
    "#     print('增加维度前:', seq.shape)\n",
    "#     print(seq[:2])\n",
    "#     print('增加维度后:', seq[:, :, np.newaxis].shape)\n",
    "#     print(seq[:2])\n",
    "#     # returned seq, res and xs: shape (batch, step, input)\n",
    "#     #np.newaxis 用来增加一个维度 变为三个维度，第三个维度将用来存上一批样本的状态\n",
    "#     return [seq[:, :, np.newaxis], res[:, :, np.newaxis], xs]\n",
    "\n",
    "\n",
    "class LSTMRNN(object):\n",
    "    def __init__(self, n_steps, input_size, output_size, cell_size,\n",
    "                 batch_size):\n",
    "        '''\n",
    "        :param n_steps: 每批数据总包含多少时间刻度\n",
    "        :param input_size: 输入数据的维度\n",
    "        :param output_size: 输出数据的维度 如果是类似价格曲线的话，应该为1\n",
    "        :param cell_size: cell的大小\n",
    "        :param batch_size: 每批次训练数据的数量\n",
    "        '''\n",
    "        self.n_steps = n_steps\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.cell_size = cell_size\n",
    "        self.batch_size = batch_size\n",
    "        with tf.name_scope('inputs'):\n",
    "            self.xs = tf.placeholder(\n",
    "                tf.float32, [None, n_steps, input_size], name='xs')  #xs 有三个维度\n",
    "            self.ys = tf.placeholder(\n",
    "                tf.float32, [None, n_steps, output_size], name='ys')  #ys 有三个维度\n",
    "        with tf.variable_scope('in_hidden'):\n",
    "            self.add_input_layer()\n",
    "        with tf.variable_scope('LSTM_cell'):\n",
    "            self.add_cell()\n",
    "        with tf.variable_scope('out_hidden'):\n",
    "            self.add_output_layer()\n",
    "        with tf.name_scope('cost'):\n",
    "            self.compute_cost()\n",
    "        with tf.name_scope('train'):\n",
    "            self.train_op = tf.train.AdamOptimizer(LR).minimize(self.cost)\n",
    "\n",
    "    #增加一个输入层\n",
    "    def add_input_layer(self, ):\n",
    "        # l_in_x:(batch*n_step, in_size),相当于把这个批次的样本串到一个长度1000的时间线上，每批次50个样本，每个样本20个时刻\n",
    "        l_in_x = tf.reshape(\n",
    "            self.xs, [-1, self.input_size], name='2_2D')  #-1 表示任意行数\n",
    "        # Ws (in_size, cell_size)\n",
    "        Ws_in = self._weight_variable([self.input_size, self.cell_size])\n",
    "        # bs (cell_size, )\n",
    "        bs_in = self._bias_variable([\n",
    "            self.cell_size,\n",
    "        ])\n",
    "        # l_in_y = (batch * n_steps, cell_size)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            l_in_y = tf.matmul(l_in_x, Ws_in) + bs_in\n",
    "        # reshape l_in_y ==> (batch, n_steps, cell_size)\n",
    "        self.l_in_y = tf.reshape(\n",
    "            l_in_y, [-1, self.n_steps, self.cell_size], name='2_3D')\n",
    "\n",
    "    #多时刻的状态叠加层 CELL\n",
    "    def add_cell(self):\n",
    "#         print('BATCH_SIZE',self.batch_size)\n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(\n",
    "            self.cell_size, forget_bias=1.0, state_is_tuple=True)\n",
    "        with tf.name_scope('initial_state'):\n",
    "            self.cell_init_state = lstm_cell.zero_state(\n",
    "                self.batch_size, dtype=tf.float32)\n",
    "        #time_major=False 表示时间主线不是第一列batch\n",
    "        self.cell_outputs, self.cell_final_state = tf.nn.dynamic_rnn(\n",
    "            lstm_cell,\n",
    "            self.l_in_y,\n",
    "            initial_state=self.cell_init_state,\n",
    "            time_major=False)\n",
    "\n",
    "    # 增加一个输出层\n",
    "    def add_output_layer(self):\n",
    "        # shape = (batch * steps, cell_size)\n",
    "        l_out_x = tf.reshape(\n",
    "            self.cell_outputs, [-1, self.cell_size], name='2_2D')\n",
    "        Ws_out = self._weight_variable([self.cell_size, self.output_size])\n",
    "        bs_out = self._bias_variable([\n",
    "            self.output_size,\n",
    "        ])\n",
    "        # shape = (batch * steps, output_size)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            self.pred = tf.matmul(l_out_x, Ws_out) + bs_out  #预测结果\n",
    "    \n",
    "    # 计算损失\n",
    "    def compute_cost(self):\n",
    "        losses = tf.contrib.legacy_seq2seq.sequence_loss_by_example(\n",
    "            [tf.reshape(self.pred, [-1], name='reshape_pred')],\n",
    "            [tf.reshape(self.ys, [-1], name='reshape_target')],\n",
    "            [tf.ones([self.batch_size * self.n_steps], dtype=tf.float32)],\n",
    "            average_across_timesteps=True,\n",
    "            softmax_loss_function=self.ms_error,\n",
    "            name='losses')\n",
    "        with tf.name_scope('average_cost'):\n",
    "            self.cost = tf.div(\n",
    "                tf.reduce_sum(losses, name='losses_sum'),\n",
    "                self.batch_size,\n",
    "                name='average_cost')\n",
    "            tf.summary.scalar('cost', self.cost)\n",
    "\n",
    "    def ms_error(self, labels, logits):\n",
    "        return tf.square(tf.subtract(labels, logits))\n",
    "\n",
    "    def _weight_variable(self, shape, name='weights'):\n",
    "        initializer = tf.random_normal_initializer(\n",
    "            mean=0.,\n",
    "            stddev=1.,\n",
    "        )\n",
    "        return tf.get_variable(shape=shape, initializer=initializer, name=name)\n",
    "\n",
    "    def _bias_variable(self, shape, name='biases'):\n",
    "        initializer = tf.constant_initializer(0.1)\n",
    "        return tf.get_variable(name=name, shape=shape, initializer=initializer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T07:29:30.776780Z",
     "start_time": "2018-12-12T07:28:23.220466Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq (20, 30, 10, 1)\n",
      "res (20, 30, 10, 1)\n",
      "0 cost:  4.9987\n",
      "10 cost:  3.8869\n",
      "20 cost:  3.9777\n",
      "30 cost:  4.0459\n",
      "40 cost:  3.9228\n",
      "50 cost:  3.189\n",
      "60 cost:  3.7168\n",
      "70 cost:  3.3718\n",
      "80 cost:  3.2141\n",
      "90 cost:  2.9967\n",
      "100 cost:  2.7817\n",
      "110 cost:  3.1389\n",
      "120 cost:  2.3358\n",
      "130 cost:  2.519\n",
      "140 cost:  2.3486\n",
      "150 cost:  2.12\n",
      "160 cost:  2.5229\n",
      "170 cost:  1.9962\n",
      "180 cost:  2.4313\n",
      "190 cost:  2.4486\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "tf.reset_default_graph()\n",
    "if __name__ == '__main__':\n",
    "    # 设置画布初始属性和内容\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80\n",
    "    axes = fig.add_subplot(1, 1, 1)\n",
    "    line3, = axes.plot(train_y[19:-1], 'r', label='实际')\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "    \n",
    "    seq, res = get_batch_boston()\n",
    "    costlist = []\n",
    "    print('seq',seq.shape)\n",
    "    print('res',res.shape)\n",
    "    BATCH_SIZE  = 30\n",
    "    model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, BATCH_SIZE)\n",
    "    sess = tf.Session()\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"logs\", sess.graph)\n",
    "    # tf.initialize_all_variables() no long valid from\n",
    "    # 2017-03-02 if using tensorflow >= 0.12\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # relocate to the local dir and run this line to view it on Chrome (http://0.0.0.0:6006/):\n",
    "    # $ tensorboard --logdir='logs'\n",
    "    for j in range(200):  #训练200次\n",
    "        pred_res = None\n",
    "        # 300\n",
    "        seq, res = get_batch_boston()\n",
    "#         print('seq',seq.shape)\n",
    "#        用于300\n",
    "        for i in range(20):\n",
    "            if i == 0:\n",
    "#                 print('if')\n",
    "                feed_dict = {\n",
    "                    model.xs: seq[i],\n",
    "                    model.ys: res[i],\n",
    "                    # create initial state\n",
    "                }\n",
    "            else:\n",
    "#                 print('else')\n",
    "                feed_dict = {\n",
    "                    model.xs: seq[i],\n",
    "                    model.ys: res[i],\n",
    "                    model.cell_init_state:\n",
    "                    state  # use last state as the initial state for this run\n",
    "                }\n",
    "#             print('se',seq[start:end].shape)\n",
    "#             start += TIME_STEPS\n",
    "#             print('start',type(start))\n",
    "#             end=start+BATCH_SIZE\n",
    "\n",
    "#         10\n",
    "#         step=0\n",
    "#         start=0\n",
    "#         end=start+BATCH_SIZE\n",
    "#         #每个内循环是100次，数据是0-60，60-120，120-180，递增\n",
    "#         while(end<len(train_x)-206):\n",
    "#             print()\n",
    "#             if start == 0:\n",
    "# #                 print('if')\n",
    "#                 feed_dict = {\n",
    "#                     model.xs: seq[start:end],\n",
    "#                     model.ys: res[start:end],\n",
    "#                     # create initial state\n",
    "#                 }\n",
    "#             else:\n",
    "# #                 print('else')\n",
    "#                 feed_dict = {\n",
    "#                     model.xs: seq[start:end],\n",
    "#                     model.ys: res[start:end],\n",
    "#                     model.cell_init_state:\n",
    "#                     state  # use last state as the initial state for this run\n",
    "#                 }\n",
    "#             print('start,end,step',start,end,step,',seq',seq[start:end].shape)\n",
    "#             start+=BATCH_SIZE\n",
    "#             end=start+BATCH_SIZE\n",
    "#             #每10步保存一次参数\n",
    "#             if step%10==0:\n",
    "#                 print(i,step,cost)\n",
    "#             step+=1\n",
    "\n",
    "            \n",
    "            _, cost, state, pred = sess.run([\n",
    "                model.train_op, model.cost, model.cell_final_state, model.pred\n",
    "            ],feed_dict=feed_dict)\n",
    "            pred_res = pred\n",
    "            \n",
    "\n",
    "\n",
    "            result = sess.run(merged, feed_dict)\n",
    "            writer.add_summary(result, i)\n",
    "        if(j % 10 ==0):\n",
    "            print('{0} cost: '.format(j), round(cost, 4))\n",
    "        BATCH_START = 0  #从头再来一遍\n",
    "        try:\n",
    "            axes.lines.remove(line1)\n",
    "            axes.lines.remove(line_c)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        costlist.append(cost)\n",
    "        line_c, = axes.plot(costlist,'y',label='cost')\n",
    "#         handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        # 返回是, 是一个Line2D的对象，无逗号是一个包含了Line2D的数组\n",
    "#         line1, = axes.plot(\n",
    "#             range(100), pred.flatten()[-100:], 'b--', label='rnn计算结果 '+str(j))\n",
    "        line1, = axes.plot(pred.flatten(), 'b--', label='rnn计算结果 '+str(j))\n",
    "        axes.grid()\n",
    "        fig.tight_layout()\n",
    "        plt.legend(handles=[line1,line3])\n",
    "        plt.title('递归神经网络')\n",
    "        plt.pause(0.01)\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    \n",
    "    # 保存模型\n",
    "#     saver = tf.train.Saver()\n",
    "#     saver.save(sess, save_dir,)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T07:44:47.268082Z",
     "start_time": "2018-12-12T07:44:19.951540Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq (20, 30, 10, 1)\n",
      "INFO:tensorflow:Restoring parameters from ./bst_save/ckpt/bst\n",
      "prev_seq (1, 10, 1)\n",
      "prev_seq_out [[[ 0.15968566]\n",
      "  [-0.10152429]\n",
      "  [ 1.32424667]\n",
      "  [ 1.18275795]\n",
      "  [ 1.48750288]\n",
      "  [ 0.6712218 ]\n",
      "  [ 0.03996443]\n",
      "  [ 0.49708184]\n",
      "  [-0.65659542]\n",
      "  [-0.39538548]]]\n",
      "prev_seq_out [array([[ 0.16351035],\n",
      "       [-0.06368324],\n",
      "       [ 1.2669452 ],\n",
      "       [ 1.2167677 ],\n",
      "       [ 1.5328723 ],\n",
      "       [ 0.7166994 ],\n",
      "       [ 0.07408087],\n",
      "       [ 0.4918877 ],\n",
      "       [-0.678943  ],\n",
      "       [-0.43444115]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.12413   ],\n",
      "       [-0.0726745 ],\n",
      "       [ 1.284955  ],\n",
      "       [ 1.2414328 ],\n",
      "       [ 1.5586842 ],\n",
      "       [ 0.72109014],\n",
      "       [ 0.07697739],\n",
      "       [ 0.48038816],\n",
      "       [-0.70061356],\n",
      "       [-0.45714402]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.10953857],\n",
      "       [-0.06753837],\n",
      "       [ 1.3210515 ],\n",
      "       [ 1.2737321 ],\n",
      "       [ 1.588334  ],\n",
      "       [ 0.7252367 ],\n",
      "       [ 0.07873495],\n",
      "       [ 0.47006458],\n",
      "       [-0.7206623 ],\n",
      "       [-0.47749972]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.0988418 ],\n",
      "       [-0.06016041],\n",
      "       [ 1.364823  ],\n",
      "       [ 1.3103124 ],\n",
      "       [ 1.6208553 ],\n",
      "       [ 0.7300404 ],\n",
      "       [ 0.08038618],\n",
      "       [ 0.46052092],\n",
      "       [-0.74041116],\n",
      "       [-0.49836534]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.08858313],\n",
      "       [-0.05271752],\n",
      "       [ 1.4150614 ],\n",
      "       [ 1.3506669 ],\n",
      "       [ 1.6560309 ],\n",
      "       [ 0.73549145],\n",
      "       [ 0.08200003],\n",
      "       [ 0.4516431 ],\n",
      "       [-0.7600595 ],\n",
      "       [-0.5202063 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.07831515],\n",
      "       [-0.04552679],\n",
      "       [ 1.4721063 ],\n",
      "       [ 1.3949761 ],\n",
      "       [ 1.6939363 ],\n",
      "       [ 0.7415753 ],\n",
      "       [ 0.08357646],\n",
      "       [ 0.44340348],\n",
      "       [-0.77959496],\n",
      "       [-0.54311013]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.06806536],\n",
      "       [-0.03860097],\n",
      "       [ 1.5364692 ],\n",
      "       [ 1.443526  ],\n",
      "       [ 1.7346854 ],\n",
      "       [ 0.7482715 ],\n",
      "       [ 0.08510329],\n",
      "       [ 0.43579412],\n",
      "       [-0.79896694],\n",
      "       [-0.5670967 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.05795057],\n",
      "       [-0.03188781],\n",
      "       [ 1.6085328 ],\n",
      "       [ 1.4965931 ],\n",
      "       [ 1.7783763 ],\n",
      "       [ 0.75554484],\n",
      "       [ 0.08655925],\n",
      "       [ 0.4288128 ],\n",
      "       [-0.8181126 ],\n",
      "       [-0.5921585 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.04811884],\n",
      "       [-0.0253049 ],\n",
      "       [ 1.6883819 ],\n",
      "       [ 1.5544047 ],\n",
      "       [ 1.825073  ],\n",
      "       [ 0.7633428 ],\n",
      "       [ 0.08791436],\n",
      "       [ 0.42246145],\n",
      "       [-0.8369589 ],\n",
      "       [-0.61826205]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.0387397 ],\n",
      "       [-0.0187432 ],\n",
      "       [ 1.775626  ],\n",
      "       [ 1.6171072 ],\n",
      "       [ 1.8747928 ],\n",
      "       [ 0.7715967 ],\n",
      "       [ 0.08913048],\n",
      "       [ 0.41674656],\n",
      "       [-0.85542023],\n",
      "       [-0.64534086]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.03000207],\n",
      "       [-0.01206727],\n",
      "       [ 1.8692172 ],\n",
      "       [ 1.6847334 ],\n",
      "       [ 1.9274931 ],\n",
      "       [ 0.78022605],\n",
      "       [ 0.09016301],\n",
      "       [ 0.41167825],\n",
      "       [-0.87339956],\n",
      "       [-0.6732893 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.02210994],\n",
      "       [-0.00511517],\n",
      "       [ 1.9673191 ],\n",
      "       [ 1.7571714 ],\n",
      "       [ 1.9830563 ],\n",
      "       [ 0.78914815],\n",
      "       [ 0.09096731],\n",
      "       [ 0.40727222],\n",
      "       [-0.890787  ],\n",
      "       [-0.701956  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.01527758],\n",
      "       [ 0.00229935],\n",
      "       [ 2.0673056 ],\n",
      "       [ 1.8341401 ],\n",
      "       [ 2.0412743 ],\n",
      "       [ 0.7982891 ],\n",
      "       [ 0.09150727],\n",
      "       [ 0.40355092],\n",
      "       [-0.9074643 ],\n",
      "       [-0.7311422 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.00972123],\n",
      "       [ 0.01038371],\n",
      "       [ 2.1659658 ],\n",
      "       [ 1.915168  ],\n",
      "       [ 2.101828  ],\n",
      "       [ 0.8075958 ],\n",
      "       [ 0.09176387],\n",
      "       [ 0.40054494],\n",
      "       [-0.9233113 ],\n",
      "       [-0.76060337]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.00564896],\n",
      "       [ 0.01936032],\n",
      "       [ 2.2599325 ],\n",
      "       [ 1.999575  ],\n",
      "       [ 2.1642702 ],\n",
      "       [ 0.8170425 ],\n",
      "       [ 0.09174301],\n",
      "       [ 0.398292  ],\n",
      "       [-0.93821234],\n",
      "       [-0.79005593]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.00324936],\n",
      "       [ 0.02946068],\n",
      "       [ 2.346237  ],\n",
      "       [ 2.0864565 ],\n",
      "       [ 2.2280083 ],\n",
      "       [ 0.826633  ],\n",
      "       [ 0.09147669],\n",
      "       [ 0.3968342 ],\n",
      "       [-0.95206946],\n",
      "       [-0.81919   ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.00268055],\n",
      "       [ 0.04091765],\n",
      "       [ 2.4228082 ],\n",
      "       [ 2.1746628 ],\n",
      "       [ 2.292303  ],\n",
      "       [ 0.83639205],\n",
      "       [ 0.09102072],\n",
      "       [ 0.39621204],\n",
      "       [-0.9648091 ],\n",
      "       [-0.8476876 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.00405927],\n",
      "       [ 0.05395927],\n",
      "       [ 2.4887402 ],\n",
      "       [ 2.2627988 ],\n",
      "       [ 2.3562846 ],\n",
      "       [ 0.84635895],\n",
      "       [ 0.09044756],\n",
      "       [ 0.39646006],\n",
      "       [-0.9763879 ],\n",
      "       [-0.87523985]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.00745495],\n",
      "       [ 0.06880237],\n",
      "       [ 2.5442517 ],\n",
      "       [ 2.349263  ],\n",
      "       [ 2.4189973 ],\n",
      "       [ 0.85657865],\n",
      "       [ 0.08984144],\n",
      "       [ 0.3976012 ],\n",
      "       [-0.98679525],\n",
      "       [-0.90156806]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.01288463],\n",
      "       [ 0.08564813],\n",
      "       [ 2.590408  ],\n",
      "       [ 2.4323452 ],\n",
      "       [ 2.4794672 ],\n",
      "       [ 0.8670991 ],\n",
      "       [ 0.08929469],\n",
      "       [ 0.3996455 ],\n",
      "       [-0.99605054],\n",
      "       [-0.9264397 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.02031304],\n",
      "       [ 0.10467763],\n",
      "       [ 2.6287522 ],\n",
      "       [ 2.5103846 ],\n",
      "       [ 2.5367837 ],\n",
      "       [ 0.8779709 ],\n",
      "       [ 0.08890791],\n",
      "       [ 0.40259033],\n",
      "       [-1.0041993 ],\n",
      "       [-0.9496829 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.02965452],\n",
      "       [ 0.12604894],\n",
      "       [ 2.6609645 ],\n",
      "       [ 2.5819542 ],\n",
      "       [ 2.5901778 ],\n",
      "       [ 0.88924855],\n",
      "       [ 0.08879252],\n",
      "       [ 0.40642428],\n",
      "       [-1.0113072 ],\n",
      "       [-0.9711942 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.04077859],\n",
      "       [ 0.14989592],\n",
      "       [ 2.6886232 ],\n",
      "       [ 2.646023  ],\n",
      "       [ 2.6390846 ],\n",
      "       [ 0.90099436],\n",
      "       [ 0.08907308],\n",
      "       [ 0.41113067],\n",
      "       [-1.017455  ],\n",
      "       [-0.99094063]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.05351759],\n",
      "       [ 0.17632897],\n",
      "       [ 2.7130697 ],\n",
      "       [ 2.7020483 ],\n",
      "       [ 2.683173  ],\n",
      "       [ 0.9132772 ],\n",
      "       [ 0.08988859],\n",
      "       [ 0.4166906 ],\n",
      "       [-1.0227324 ],\n",
      "       [-1.0089548 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.0676765 ],\n",
      "       [ 0.20543899],\n",
      "       [ 2.7353625 ],\n",
      "       [ 2.749985  ],\n",
      "       [ 2.7223454 ],\n",
      "       [ 0.9261732 ],\n",
      "       [ 0.09139396],\n",
      "       [ 0.42308617],\n",
      "       [-1.0272338 ],\n",
      "       [-1.0253278 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.08304204],\n",
      "       [ 0.23730342],\n",
      "       [ 2.7562833 ],\n",
      "       [ 2.7902102 ],\n",
      "       [ 2.756712  ],\n",
      "       [ 0.9397643 ],\n",
      "       [ 0.0937586 ],\n",
      "       [ 0.43030256],\n",
      "       [-1.0310541 ],\n",
      "       [-1.0401965 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.09939332],\n",
      "       [ 0.27199614],\n",
      "       [ 2.7763698 ],\n",
      "       [ 2.8234046 ],\n",
      "       [ 2.7865434 ],\n",
      "       [ 0.9541351 ],\n",
      "       [ 0.09716643],\n",
      "       [ 0.43832946],\n",
      "       [-1.0342854 ],\n",
      "       [-1.05373   ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.11651035],\n",
      "       [ 0.30959904],\n",
      "       [ 2.7959638 ],\n",
      "       [ 2.8504221 ],\n",
      "       [ 2.8122249 ],\n",
      "       [ 0.9693737 ],\n",
      "       [ 0.1018144 ],\n",
      "       [ 0.44716167],\n",
      "       [-1.0370127 ],\n",
      "       [-1.0661173 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.1341814 ],\n",
      "       [ 0.35021728],\n",
      "       [ 2.8152542 ],\n",
      "       [ 2.8721776 ],\n",
      "       [ 2.8342037 ],\n",
      "       [ 0.9855695 ],\n",
      "       [ 0.10791166],\n",
      "       [ 0.4568001 ],\n",
      "       [-1.0393134 ],\n",
      "       [-1.0775557 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.15220965],\n",
      "       [ 0.39399612],\n",
      "       [ 2.834322  ],\n",
      "       [ 2.8895626 ],\n",
      "       [ 2.8529513 ],\n",
      "       [ 1.0028136 ],\n",
      "       [ 0.11567868],\n",
      "       [ 0.4672528 ],\n",
      "       [-1.041253  ],\n",
      "       [-1.0882406 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.17041685],\n",
      "       [ 0.44114095],\n",
      "       [ 2.8531764 ],\n",
      "       [ 2.903392  ],\n",
      "       [ 2.8689318 ],\n",
      "       [ 1.0211971 ],\n",
      "       [ 0.12534608],\n",
      "       [ 0.47853553],\n",
      "       [-1.0428842 ],\n",
      "       [-1.0983608 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.18864675],\n",
      "       [ 0.49193895],\n",
      "       [ 2.8717816 ],\n",
      "       [ 2.9143806 ],\n",
      "       [ 2.8825808 ],\n",
      "       [ 1.040813  ],\n",
      "       [ 0.13715227],\n",
      "       [ 0.4906726 ],\n",
      "       [-1.0442454 ],\n",
      "       [-1.1080909 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.20676698],\n",
      "       [ 0.546785  ],\n",
      "       [ 2.8900855 ],\n",
      "       [ 2.9231327 ],\n",
      "       [ 2.8942955 ],\n",
      "       [ 1.0617558 ],\n",
      "       [ 0.15134181],\n",
      "       [ 0.5036993 ],\n",
      "       [-1.0453566 ],\n",
      "       [-1.11759   ]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_seq_out [array([[ 0.22467043],\n",
      "       [ 0.60621005],\n",
      "       [ 2.9080317 ],\n",
      "       [ 2.930147  ],\n",
      "       [ 2.9044247 ],\n",
      "       [ 1.0841221 ],\n",
      "       [ 0.16816075],\n",
      "       [ 0.5176633 ],\n",
      "       [-1.0462208 ],\n",
      "       [-1.1270001 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.24227615],\n",
      "       [ 0.67091197],\n",
      "       [ 2.9255743 ],\n",
      "       [ 2.9358263 ],\n",
      "       [ 2.9132724 ],\n",
      "       [ 1.1080099 ],\n",
      "       [ 0.18785079],\n",
      "       [ 0.5326264 ],\n",
      "       [-1.0468184 ],\n",
      "       [-1.1364442 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.25953072],\n",
      "       [ 0.74179107],\n",
      "       [ 2.9426796 ],\n",
      "       [ 2.9404917 ],\n",
      "       [ 2.9210968 ],\n",
      "       [ 1.1335195 ],\n",
      "       [ 0.21064062],\n",
      "       [ 0.5486662 ],\n",
      "       [-1.0471069 ],\n",
      "       [-1.1460261 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.27640933],\n",
      "       [ 0.8199845 ],\n",
      "       [ 2.9593306 ],\n",
      "       [ 2.9443922 ],\n",
      "       [ 2.9281156 ],\n",
      "       [ 1.1607509 ],\n",
      "       [ 0.23673435],\n",
      "       [ 0.5658765 ],\n",
      "       [-1.0470163 ],\n",
      "       [-1.1558297 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.29291815],\n",
      "       [ 0.9068937 ],\n",
      "       [ 2.9755158 ],\n",
      "       [ 2.9477167 ],\n",
      "       [ 2.9345076 ],\n",
      "       [ 1.1897999 ],\n",
      "       [ 0.26629382],\n",
      "       [ 0.5843664 ],\n",
      "       [-1.046448  ],\n",
      "       [-1.1659154 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.30909818],\n",
      "       [ 1.0041952 ],\n",
      "       [ 2.9912179 ],\n",
      "       [ 2.950605  ],\n",
      "       [ 2.9404182 ],\n",
      "       [ 1.2207553 ],\n",
      "       [ 0.29941732],\n",
      "       [ 0.6042534 ],\n",
      "       [-1.0452724 ],\n",
      "       [-1.1763175 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.32503033],\n",
      "       [ 1.1138023 ],\n",
      "       [ 3.006394  ],\n",
      "       [ 2.9531534 ],\n",
      "       [ 2.9459608 ],\n",
      "       [ 1.2536865 ],\n",
      "       [ 0.33611095],\n",
      "       [ 0.6256552 ],\n",
      "       [-1.0433301 ],\n",
      "       [-1.187036  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.34084147],\n",
      "       [ 1.2377415 ],\n",
      "       [ 3.0209415 ],\n",
      "       [ 2.9554222 ],\n",
      "       [ 2.9512155 ],\n",
      "       [ 1.288633  ],\n",
      "       [ 0.37625688],\n",
      "       [ 0.6486705 ],\n",
      "       [-1.0404382 ],\n",
      "       [-1.198031  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.35671145],\n",
      "       [ 1.3778677 ],\n",
      "       [ 3.0346668 ],\n",
      "       [ 2.957441  ],\n",
      "       [ 2.956231  ],\n",
      "       [ 1.3255892 ],\n",
      "       [ 0.41958034],\n",
      "       [ 0.67335343],\n",
      "       [-1.0364038 ],\n",
      "       [-1.2092117 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.37287986],\n",
      "       [ 1.5353396 ],\n",
      "       [ 3.0472455 ],\n",
      "       [ 2.959211  ],\n",
      "       [ 2.9610226 ],\n",
      "       [ 1.3644938 ],\n",
      "       [ 0.46562636],\n",
      "       [ 0.69968516],\n",
      "       [-1.0310465 ],\n",
      "       [-1.2204325 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.38964707],\n",
      "       [ 1.709793  ],\n",
      "       [ 3.0582116 ],\n",
      "       [ 2.9607134 ],\n",
      "       [ 2.9655735 ],\n",
      "       [ 1.4052287 ],\n",
      "       [ 0.51376206],\n",
      "       [ 0.7275496 ],\n",
      "       [-1.0242296 ],\n",
      "       [-1.2314942 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.40736687],\n",
      "       [ 1.8982903 ],\n",
      "       [ 3.0669942 ],\n",
      "       [ 2.9619188 ],\n",
      "       [ 2.9698405 ],\n",
      "       [ 1.4476403 ],\n",
      "       [ 0.5632248 ],\n",
      "       [ 0.756732  ],\n",
      "       [-1.0158871 ],\n",
      "       [-1.2421591 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.4264263 ],\n",
      "       [ 2.0944448 ],\n",
      "       [ 3.0730288 ],\n",
      "       [ 2.9628072 ],\n",
      "       [ 2.97377   ],\n",
      "       [ 1.4915888 ],\n",
      "       [ 0.61322594],\n",
      "       [ 0.78695554],\n",
      "       [-1.0060364 ],\n",
      "       [-1.2521769 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.44721162],\n",
      "       [ 2.288496  ],\n",
      "       [ 3.0759437 ],\n",
      "       [ 2.9633887 ],\n",
      "       [ 2.9773178 ],\n",
      "       [ 1.5370145 ],\n",
      "       [ 0.6630896 ],\n",
      "       [ 0.81795466],\n",
      "       [-0.9947589 ],\n",
      "       [-1.2613189 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.47007495],\n",
      "       [ 2.469083  ],\n",
      "       [ 3.0757449 ],\n",
      "       [ 2.9637196 ],\n",
      "       [ 2.9804704 ],\n",
      "       [ 1.5839883 ],\n",
      "       [ 0.71237105],\n",
      "       [ 0.8495553 ],\n",
      "       [-0.9821587 ],\n",
      "       [-1.269403  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.49531347],\n",
      "       [ 2.6264315 ],\n",
      "       [ 3.0728812 ],\n",
      "       [ 2.9638984 ],\n",
      "       [ 2.9832463 ],\n",
      "       [ 1.6327163 ],\n",
      "       [ 0.76089734],\n",
      "       [ 0.88171905],\n",
      "       [-0.9683184 ],\n",
      "       [-1.276304  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.5231739 ],\n",
      "       [ 2.7552423 ],\n",
      "       [ 3.068129  ],\n",
      "       [ 2.9640424 ],\n",
      "       [ 2.985691  ],\n",
      "       [ 1.6834974 ],\n",
      "       [ 0.8087149 ],\n",
      "       [ 0.9145296 ],\n",
      "       [-0.95327884],\n",
      "       [-1.281951  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.5538795 ],\n",
      "       [ 2.8554897 ],\n",
      "       [ 3.062359  ],\n",
      "       [ 2.964256  ],\n",
      "       [ 2.9878612 ],\n",
      "       [ 1.7366617 ],\n",
      "       [ 0.85599476],\n",
      "       [ 0.948143  ],\n",
      "       [-0.9370442 ],\n",
      "       [-1.2863117 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.5876606 ],\n",
      "       [ 2.9310114 ],\n",
      "       [ 3.0563195 ],\n",
      "       [ 2.9646156 ],\n",
      "       [ 2.9898129 ],\n",
      "       [ 1.7925129 ],\n",
      "       [ 0.9029481 ],\n",
      "       [ 0.98273623],\n",
      "       [-0.9196015 ],\n",
      "       [-1.2893776 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.62477756],\n",
      "       [ 2.98727   ],\n",
      "       [ 3.0505292 ],\n",
      "       [ 2.9651628 ],\n",
      "       [ 2.991594  ],\n",
      "       [ 1.8512956 ],\n",
      "       [ 0.9497772 ],\n",
      "       [ 1.0184765 ],\n",
      "       [-0.9009345 ],\n",
      "       [-1.2911482 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.66553086],\n",
      "       [ 3.0296035 ],\n",
      "       [ 3.0452724 ],\n",
      "       [ 2.9659128 ],\n",
      "       [ 2.9932442 ],\n",
      "       [ 1.9131664 ],\n",
      "       [ 0.9966601 ],\n",
      "       [ 1.0555104 ],\n",
      "       [-0.8810337 ],\n",
      "       [-1.2916217 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.7102572 ],\n",
      "       [ 3.0623627 ],\n",
      "       [ 3.040653  ],\n",
      "       [ 2.9668612 ],\n",
      "       [ 2.9947963 ],\n",
      "       [ 1.9781705 ],\n",
      "       [ 1.0437497 ],\n",
      "       [ 1.0939647 ],\n",
      "       [-0.85989994],\n",
      "       [-1.2907892 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.7593212 ],\n",
      "       [ 3.0887265 ],\n",
      "       [ 3.0366585 ],\n",
      "       [ 2.9679947 ],\n",
      "       [ 2.9962745 ],\n",
      "       [ 2.0462132 ],\n",
      "       [ 1.0911803 ],\n",
      "       [ 1.1339533 ],\n",
      "       [-0.83754337],\n",
      "       [-1.2886318 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.813102 ],\n",
      "       [ 3.110846 ],\n",
      "       [ 3.0332122],\n",
      "       [ 2.9692945],\n",
      "       [ 2.9976988],\n",
      "       [ 2.117029 ],\n",
      "       [ 1.1390736],\n",
      "       [ 1.1755842],\n",
      "       [-0.8139821],\n",
      "       [-1.2851212]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.87198013],\n",
      "       [ 3.1300821 ],\n",
      "       [ 3.0302107 ],\n",
      "       [ 2.9707408 ],\n",
      "       [ 2.9990816 ],\n",
      "       [ 2.19015   ],\n",
      "       [ 1.187543  ],\n",
      "       [ 1.2189649 ],\n",
      "       [-0.78924197],\n",
      "       [-1.2802228 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 0.9363242 ],\n",
      "       [ 3.147234  ],\n",
      "       [ 3.0275488 ],\n",
      "       [ 2.9723127 ],\n",
      "       [ 3.0004318 ],\n",
      "       [ 2.264885  ],\n",
      "       [ 1.2366982 ],\n",
      "       [ 1.2642076 ],\n",
      "       [-0.76335305],\n",
      "       [-1.2738988 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.0064799 ],\n",
      "       [ 3.1627178 ],\n",
      "       [ 3.0251298 ],\n",
      "       [ 2.9739892 ],\n",
      "       [ 3.0017514 ],\n",
      "       [ 2.340314  ],\n",
      "       [ 1.2866474 ],\n",
      "       [ 1.3114325 ],\n",
      "       [-0.73634815],\n",
      "       [-1.2661126 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.0827599],\n",
      "       [ 3.176701 ],\n",
      "       [ 3.022874 ],\n",
      "       [ 2.975748 ],\n",
      "       [ 3.0030391],\n",
      "       [ 2.4153166],\n",
      "       [ 1.3375014],\n",
      "       [ 1.3607725],\n",
      "       [-0.7082608],\n",
      "       [-1.2568336]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.1654367 ],\n",
      "       [ 3.1891985 ],\n",
      "       [ 3.0207176 ],\n",
      "       [ 2.977566  ],\n",
      "       [ 3.0042877 ],\n",
      "       [ 2.4886334 ],\n",
      "       [ 1.3893754 ],\n",
      "       [ 1.4123753 ],\n",
      "       [-0.67912185],\n",
      "       [-1.2460418 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.2547336 ],\n",
      "       [ 3.2001429 ],\n",
      "       [ 3.0186126 ],\n",
      "       [ 2.9794178 ],\n",
      "       [ 3.005487  ],\n",
      "       [ 2.558962  ],\n",
      "       [ 1.4423964 ],\n",
      "       [ 1.4664047 ],\n",
      "       [-0.64895767],\n",
      "       [-1.2337348 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.3508086],\n",
      "       [ 3.2094364],\n",
      "       [ 3.0165265],\n",
      "       [ 2.981278 ],\n",
      "       [ 3.006623 ],\n",
      "       [ 2.6250763],\n",
      "       [ 1.496702 ],\n",
      "       [ 1.5230398],\n",
      "       [-0.6177885],\n",
      "       [-1.2199332]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.4537235 ],\n",
      "       [ 3.2169838 ],\n",
      "       [ 3.0144403 ],\n",
      "       [ 2.9831192 ],\n",
      "       [ 3.0076807 ],\n",
      "       [ 2.685943  ],\n",
      "       [ 1.5524437 ],\n",
      "       [ 1.5824759 ],\n",
      "       [-0.58562523],\n",
      "       [-1.2046857 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.563388 ],\n",
      "       [ 3.222718 ],\n",
      "       [ 3.0123448],\n",
      "       [ 2.9849148],\n",
      "       [ 3.0086434],\n",
      "       [ 2.7408173],\n",
      "       [ 1.6097873],\n",
      "       [ 1.6449143],\n",
      "       [-0.5524686],\n",
      "       [-1.1880784]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.6794661],\n",
      "       [ 3.226612 ],\n",
      "       [ 3.0102394],\n",
      "       [ 2.9866393],\n",
      "       [ 3.0094962],\n",
      "       [ 2.7892919],\n",
      "       [ 1.6689082],\n",
      "       [ 1.7105535],\n",
      "       [-0.5183075],\n",
      "       [-1.1702391]], dtype=float32)]\n",
      "prev_seq_out [array([[ 1.801251  ],\n",
      "       [ 3.2286823 ],\n",
      "       [ 3.0081306 ],\n",
      "       [ 2.9882703 ],\n",
      "       [ 3.0102267 ],\n",
      "       [ 2.8312962 ],\n",
      "       [ 1.7299855 ],\n",
      "       [ 1.7795706 ],\n",
      "       [-0.48311502],\n",
      "       [-1.151342  ]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_seq_out [array([[ 1.9275147 ],\n",
      "       [ 3.2289877 ],\n",
      "       [ 3.006031  ],\n",
      "       [ 2.9897895 ],\n",
      "       [ 3.010827  ],\n",
      "       [ 2.8670547 ],\n",
      "       [ 1.7931889 ],\n",
      "       [ 1.8520933 ],\n",
      "       [-0.44684464],\n",
      "       [-1.131612  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.0563788 ],\n",
      "       [ 3.2276294 ],\n",
      "       [ 3.003958  ],\n",
      "       [ 2.9911857 ],\n",
      "       [ 3.0112953 ],\n",
      "       [ 2.8970146 ],\n",
      "       [ 1.8586636 ],\n",
      "       [ 1.9281616 ],\n",
      "       [-0.40942276],\n",
      "       [-1.111321  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.185272  ],\n",
      "       [ 3.224747  ],\n",
      "       [ 3.0019352 ],\n",
      "       [ 2.9924529 ],\n",
      "       [ 3.0116372 ],\n",
      "       [ 2.9217672 ],\n",
      "       [ 1.9265045 ],\n",
      "       [ 2.0076754 ],\n",
      "       [-0.37074405],\n",
      "       [-1.0907809 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.3110473],\n",
      "       [ 3.220521 ],\n",
      "       [ 2.9999895],\n",
      "       [ 2.9935942],\n",
      "       [ 3.0118642],\n",
      "       [ 2.9419727],\n",
      "       [ 1.9967258],\n",
      "       [ 2.090335 ],\n",
      "       [-0.3306669],\n",
      "       [-1.070333 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.4302974],\n",
      "       [ 3.2151754],\n",
      "       [ 2.9981515],\n",
      "       [ 2.9946172],\n",
      "       [ 3.0119967],\n",
      "       [ 2.9583018],\n",
      "       [ 2.069222 ],\n",
      "       [ 2.1755729],\n",
      "       [-0.2890166],\n",
      "       [-1.0503281]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.539832  ],\n",
      "       [ 3.2089715 ],\n",
      "       [ 2.99645   ],\n",
      "       [ 2.9955363 ],\n",
      "       [ 3.012057  ],\n",
      "       [ 2.9713922 ],\n",
      "       [ 2.1437247 ],\n",
      "       [ 2.262501  ],\n",
      "       [-0.24559598],\n",
      "       [-1.0311095 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.637176  ],\n",
      "       [ 3.2021954 ],\n",
      "       [ 2.9949124 ],\n",
      "       [ 2.996368  ],\n",
      "       [ 3.0120704 ],\n",
      "       [ 2.9818223 ],\n",
      "       [ 2.219763  ],\n",
      "       [ 2.3498893 ],\n",
      "       [-0.20020454],\n",
      "       [-1.012989  ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.720916  ],\n",
      "       [ 3.195134  ],\n",
      "       [ 2.9935582 ],\n",
      "       [ 2.9971292 ],\n",
      "       [ 3.0120609 ],\n",
      "       [ 2.9900975 ],\n",
      "       [ 2.2966385 ],\n",
      "       [ 2.4362006 ],\n",
      "       [-0.15266232],\n",
      "       [-0.99622625]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.7907834 ],\n",
      "       [ 3.1880474 ],\n",
      "       [ 2.992399  ],\n",
      "       [ 2.9978352 ],\n",
      "       [ 3.0120485 ],\n",
      "       [ 2.996648  ],\n",
      "       [ 2.373424  ],\n",
      "       [ 2.519697  ],\n",
      "       [-0.10283528],\n",
      "       [-0.9810055 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.847482  ],\n",
      "       [ 3.1811497 ],\n",
      "       [ 2.9914339 ],\n",
      "       [ 2.9984987 ],\n",
      "       [ 3.0120482 ],\n",
      "       [ 3.0018287 ],\n",
      "       [ 2.4490032 ],\n",
      "       [ 2.5986128 ],\n",
      "       [-0.05065589],\n",
      "       [-0.9674143 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.8923717 ],\n",
      "       [ 3.1745918 ],\n",
      "       [ 2.990656  ],\n",
      "       [ 2.9991283 ],\n",
      "       [ 3.0120707 ],\n",
      "       [ 3.0059292 ],\n",
      "       [ 2.522143  ],\n",
      "       [ 2.6713645 ],\n",
      "       [ 0.00386448],\n",
      "       [-0.9554278 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.9271314 ],\n",
      "       [ 3.1684675 ],\n",
      "       [ 2.990049  ],\n",
      "       [ 2.9997315 ],\n",
      "       [ 3.0121224 ],\n",
      "       [ 3.0091834 ],\n",
      "       [ 2.5916054 ],\n",
      "       [ 2.7367394 ],\n",
      "       [ 0.06062855],\n",
      "       [-0.94490045]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.953494  ],\n",
      "       [ 3.1628206 ],\n",
      "       [ 2.9895935 ],\n",
      "       [ 3.0003123 ],\n",
      "       [ 3.012206  ],\n",
      "       [ 3.011776  ],\n",
      "       [ 2.6562712 ],\n",
      "       [ 2.7940254 ],\n",
      "       [ 0.11945535],\n",
      "       [-0.9355708 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.9730778 ],\n",
      "       [ 3.1576564 ],\n",
      "       [ 2.9892693 ],\n",
      "       [ 3.0008743 ],\n",
      "       [ 3.0123236 ],\n",
      "       [ 3.0138552 ],\n",
      "       [ 2.7152526 ],\n",
      "       [ 2.84304   ],\n",
      "       [ 0.18008788],\n",
      "       [-0.92707986]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.9873054 ],\n",
      "       [ 3.1529553 ],\n",
      "       [ 2.9890566 ],\n",
      "       [ 3.0014217 ],\n",
      "       [ 3.0124753 ],\n",
      "       [ 3.0155387 ],\n",
      "       [ 2.7679734 ],\n",
      "       [ 2.8840733 ],\n",
      "       [ 0.24220438],\n",
      "       [-0.9190001 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 2.997382  ],\n",
      "       [ 3.1486835 ],\n",
      "       [ 2.9889388 ],\n",
      "       [ 3.001958  ],\n",
      "       [ 3.012661  ],\n",
      "       [ 3.0169187 ],\n",
      "       [ 2.8141978 ],\n",
      "       [ 2.9177694 ],\n",
      "       [ 0.30543643],\n",
      "       [-0.9108727 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.004305  ],\n",
      "       [ 3.1447988 ],\n",
      "       [ 2.988903  ],\n",
      "       [ 3.0024886 ],\n",
      "       [ 3.0128825 ],\n",
      "       [ 3.0180676 ],\n",
      "       [ 2.854011  ],\n",
      "       [ 2.9449875 ],\n",
      "       [ 0.36938965],\n",
      "       [-0.9022459 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0088882],\n",
      "       [ 3.1412556],\n",
      "       [ 2.988939 ],\n",
      "       [ 3.0030186],\n",
      "       [ 3.0131402],\n",
      "       [ 3.0190454],\n",
      "       [ 2.8877597],\n",
      "       [ 2.9666748],\n",
      "       [ 0.4336689],\n",
      "       [-0.8927075]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0117834 ],\n",
      "       [ 3.1380057 ],\n",
      "       [ 2.9890394 ],\n",
      "       [ 3.0035534 ],\n",
      "       [ 3.0134363 ],\n",
      "       [ 3.0198972 ],\n",
      "       [ 2.9159746 ],\n",
      "       [ 2.9837666 ],\n",
      "       [ 0.497903  ],\n",
      "       [-0.88190967]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0135093],\n",
      "       [ 3.1350007],\n",
      "       [ 2.9891977],\n",
      "       [ 3.0040984],\n",
      "       [ 3.013771 ],\n",
      "       [ 3.0206597],\n",
      "       [ 2.9392912],\n",
      "       [ 2.9971259],\n",
      "       [ 0.5617685],\n",
      "       [-0.8695818]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.014468 ],\n",
      "       [ 3.1321905],\n",
      "       [ 2.9894094],\n",
      "       [ 3.0046582],\n",
      "       [ 3.0141451],\n",
      "       [ 3.0213616],\n",
      "       [ 2.9583795],\n",
      "       [ 3.0075076],\n",
      "       [ 0.6250079],\n",
      "       [-0.8555319]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.014965 ],\n",
      "       [ 3.129526 ],\n",
      "       [ 2.9896703],\n",
      "       [ 3.0052364],\n",
      "       [ 3.0145593],\n",
      "       [ 3.0220242],\n",
      "       [ 2.973893 ],\n",
      "       [ 3.0155494],\n",
      "       [ 0.6874415],\n",
      "       [-0.8396386]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0152252 ],\n",
      "       [ 3.1269605 ],\n",
      "       [ 2.9899766 ],\n",
      "       [ 3.005836  ],\n",
      "       [ 3.015013  ],\n",
      "       [ 3.022664  ],\n",
      "       [ 2.986436  ],\n",
      "       [ 3.0217743 ],\n",
      "       [ 0.7489714 ],\n",
      "       [-0.82183784]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0154073 ],\n",
      "       [ 3.1244483 ],\n",
      "       [ 2.9903245 ],\n",
      "       [ 3.0064585 ],\n",
      "       [ 3.015505  ],\n",
      "       [ 3.023294  ],\n",
      "       [ 2.9965448 ],\n",
      "       [ 3.0266025 ],\n",
      "       [ 0.80957925],\n",
      "       [-0.80210537]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0156174 ],\n",
      "       [ 3.1219482 ],\n",
      "       [ 2.9907098 ],\n",
      "       [ 3.0071054 ],\n",
      "       [ 3.0160346 ],\n",
      "       [ 3.023923  ],\n",
      "       [ 3.0046823 ],\n",
      "       [ 3.0303667 ],\n",
      "       [ 0.869319  ],\n",
      "       [-0.78043777]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.015922  ],\n",
      "       [ 3.1194222 ],\n",
      "       [ 2.9911299 ],\n",
      "       [ 3.007777  ],\n",
      "       [ 3.0166004 ],\n",
      "       [ 3.0245576 ],\n",
      "       [ 3.0112374 ],\n",
      "       [ 3.033327  ],\n",
      "       [ 0.92830753],\n",
      "       [-0.7568373 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0163586 ],\n",
      "       [ 3.1168377 ],\n",
      "       [ 2.9915814 ],\n",
      "       [ 3.0084739 ],\n",
      "       [ 3.0172007 ],\n",
      "       [ 3.0252035 ],\n",
      "       [ 3.016534  ],\n",
      "       [ 3.0356843 ],\n",
      "       [ 0.98671633],\n",
      "       [-0.73129666]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0169468],\n",
      "       [ 3.1141658],\n",
      "       [ 2.9920614],\n",
      "       [ 3.0091965],\n",
      "       [ 3.0178347],\n",
      "       [ 3.0258644],\n",
      "       [ 3.020835 ],\n",
      "       [ 3.0375934],\n",
      "       [ 1.0447606],\n",
      "       [-0.7037873]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0176923],\n",
      "       [ 3.1113832],\n",
      "       [ 2.9925687],\n",
      "       [ 3.0099452],\n",
      "       [ 3.018501 ],\n",
      "       [ 3.0265431],\n",
      "       [ 3.0243537],\n",
      "       [ 3.0391717],\n",
      "       [ 1.1026919],\n",
      "       [-0.6742502]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.018596  ],\n",
      "       [ 3.10847   ],\n",
      "       [ 2.9931033 ],\n",
      "       [ 3.0107207 ],\n",
      "       [ 3.0192003 ],\n",
      "       [ 3.0272427 ],\n",
      "       [ 3.0272627 ],\n",
      "       [ 3.0405092 ],\n",
      "       [ 1.1607926 ],\n",
      "       [-0.64258784]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0196557 ],\n",
      "       [ 3.10541   ],\n",
      "       [ 2.9936643 ],\n",
      "       [ 3.0115252 ],\n",
      "       [ 3.0199323 ],\n",
      "       [ 3.027966  ],\n",
      "       [ 3.0296993 ],\n",
      "       [ 3.0416756 ],\n",
      "       [ 1.2193723 ],\n",
      "       [-0.60865813]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.02087  ],\n",
      "       [ 3.1021895],\n",
      "       [ 2.9942544],\n",
      "       [ 3.0123606],\n",
      "       [ 3.0206993],\n",
      "       [ 3.028717 ],\n",
      "       [ 3.0317738],\n",
      "       [ 3.0427227],\n",
      "       [ 1.2787629],\n",
      "       [-0.5722684]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0222414],\n",
      "       [ 3.0987992],\n",
      "       [ 2.9948752],\n",
      "       [ 3.0132298],\n",
      "       [ 3.0215037],\n",
      "       [ 3.0294988],\n",
      "       [ 3.033574 ],\n",
      "       [ 3.043692 ],\n",
      "       [ 1.3393185],\n",
      "       [-0.533169 ]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0237765 ],\n",
      "       [ 3.09523   ],\n",
      "       [ 2.995532  ],\n",
      "       [ 3.0141375 ],\n",
      "       [ 3.022348  ],\n",
      "       [ 3.0303164 ],\n",
      "       [ 3.0351706 ],\n",
      "       [ 3.044615  ],\n",
      "       [ 1.4014121 ],\n",
      "       [-0.49104792]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_seq_out [array([[ 3.0254862 ],\n",
      "       [ 3.0914788 ],\n",
      "       [ 2.9962308 ],\n",
      "       [ 3.015089  ],\n",
      "       [ 3.023238  ],\n",
      "       [ 3.0311744 ],\n",
      "       [ 3.0366206 ],\n",
      "       [ 3.0455177 ],\n",
      "       [ 1.4654322 ],\n",
      "       [-0.44552487]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0273893 ],\n",
      "       [ 3.087544  ],\n",
      "       [ 2.9969792 ],\n",
      "       [ 3.0160916 ],\n",
      "       [ 3.0241795 ],\n",
      "       [ 3.032081  ],\n",
      "       [ 3.037972  ],\n",
      "       [ 3.0464213 ],\n",
      "       [ 1.5317774 ],\n",
      "       [-0.39614677]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0295105 ],\n",
      "       [ 3.0834317 ],\n",
      "       [ 2.997788  ],\n",
      "       [ 3.0171537 ],\n",
      "       [ 3.0251806 ],\n",
      "       [ 3.033043  ],\n",
      "       [ 3.039263  ],\n",
      "       [ 3.0473442 ],\n",
      "       [ 1.600848  ],\n",
      "       [-0.34238565]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.031884  ],\n",
      "       [ 3.079155  ],\n",
      "       [ 2.9986715 ],\n",
      "       [ 3.0182874 ],\n",
      "       [ 3.0262518 ],\n",
      "       [ 3.0340703 ],\n",
      "       [ 3.0405297 ],\n",
      "       [ 3.048304  ],\n",
      "       [ 1.6730288 ],\n",
      "       [-0.28364265]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.0345519 ],\n",
      "       [ 3.0747397 ],\n",
      "       [ 2.9996486 ],\n",
      "       [ 3.019506  ],\n",
      "       [ 3.0274053 ],\n",
      "       [ 3.0351758 ],\n",
      "       [ 3.0418024 ],\n",
      "       [ 3.049318  ],\n",
      "       [ 1.748667  ],\n",
      "       [-0.21926324]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.037567  ],\n",
      "       [ 3.0702271 ],\n",
      "       [ 3.0007427 ],\n",
      "       [ 3.0208278 ],\n",
      "       [ 3.0286577 ],\n",
      "       [ 3.0363753 ],\n",
      "       [ 3.0431108 ],\n",
      "       [ 3.0504038 ],\n",
      "       [ 1.8280356 ],\n",
      "       [-0.14857201]], dtype=float32)]\n",
      "prev_seq_out [array([[ 3.040988  ],\n",
      "       [ 3.0656807 ],\n",
      "       [ 3.0019836 ],\n",
      "       [ 3.0222747 ],\n",
      "       [ 3.030028  ],\n",
      "       [ 3.0376866 ],\n",
      "       [ 3.044484  ],\n",
      "       [ 3.0515823 ],\n",
      "       [ 1.9112861 ],\n",
      "       [-0.07093291]], dtype=float32)]\n",
      "prev_seq_out [array([[3.044883  ],\n",
      "       [3.06119   ],\n",
      "       [3.003411  ],\n",
      "       [3.0238743 ],\n",
      "       [3.0315418 ],\n",
      "       [3.039133  ],\n",
      "       [3.0459533 ],\n",
      "       [3.0528753 ],\n",
      "       [1.9983861 ],\n",
      "       [0.01415469]], dtype=float32)]\n",
      "prev_seq_out [array([[3.0493245 ],\n",
      "       [3.0568724 ],\n",
      "       [3.0050707 ],\n",
      "       [3.0256596 ],\n",
      "       [3.033229  ],\n",
      "       [3.0407426 ],\n",
      "       [3.0475519 ],\n",
      "       [3.0543091 ],\n",
      "       [2.0890453 ],\n",
      "       [0.10692687]], dtype=float32)]\n",
      "prev_seq_out [array([[3.054384  ],\n",
      "       [3.0528753 ],\n",
      "       [3.007019  ],\n",
      "       [3.0276706 ],\n",
      "       [3.0351257 ],\n",
      "       [3.0425491 ],\n",
      "       [3.0493162 ],\n",
      "       [3.0559146 ],\n",
      "       [2.182641  ],\n",
      "       [0.20721634]], dtype=float32)]\n",
      "prev_seq_out [array([[3.060125  ],\n",
      "       [3.0493639 ],\n",
      "       [3.0093195 ],\n",
      "       [3.029953  ],\n",
      "       [3.0372732 ],\n",
      "       [3.0445905 ],\n",
      "       [3.051286  ],\n",
      "       [3.057725  ],\n",
      "       [2.27816   ],\n",
      "       [0.31434828]], dtype=float32)]\n",
      "prev_seq_out [array([[3.0665932 ],\n",
      "       [3.0465064 ],\n",
      "       [3.012037  ],\n",
      "       [3.0325556 ],\n",
      "       [3.0397162 ],\n",
      "       [3.0469067 ],\n",
      "       [3.0535018 ],\n",
      "       [3.059776  ],\n",
      "       [2.3741796 ],\n",
      "       [0.42713857]], dtype=float32)]\n",
      "prev_seq_out [array([[3.073799 ],\n",
      "       [3.0444536],\n",
      "       [3.015235 ],\n",
      "       [3.035524 ],\n",
      "       [3.0424964],\n",
      "       [3.0495372],\n",
      "       [3.0560024],\n",
      "       [3.0621014],\n",
      "       [2.4689178],\n",
      "       [0.5440423]], dtype=float32)]\n",
      "prev_seq_out [array([[3.0817053],\n",
      "       [3.0433192],\n",
      "       [3.0189626],\n",
      "       [3.0388982],\n",
      "       [3.0456512],\n",
      "       [3.052515 ],\n",
      "       [3.0588205],\n",
      "       [3.0647295],\n",
      "       [2.5603719],\n",
      "       [0.6634345]], dtype=float32)]\n",
      "prev_seq_out [array([[3.0902193 ],\n",
      "       [3.043168  ],\n",
      "       [3.023251  ],\n",
      "       [3.0427034 ],\n",
      "       [3.0492036 ],\n",
      "       [3.055861  ],\n",
      "       [3.061976  ],\n",
      "       [3.0676758 ],\n",
      "       [2.6465335 ],\n",
      "       [0.78393304]], dtype=float32)]\n",
      "prev_seq_out [array([[3.0991936],\n",
      "       [3.044018 ],\n",
      "       [3.0281057],\n",
      "       [3.0469468],\n",
      "       [3.0531602],\n",
      "       [3.0595803],\n",
      "       [3.0654736],\n",
      "       [3.0709436],\n",
      "       [2.7256434],\n",
      "       [0.9046364]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1084404],\n",
      "       [3.045844 ],\n",
      "       [3.0335064],\n",
      "       [3.051614 ],\n",
      "       [3.0575092],\n",
      "       [3.0636609],\n",
      "       [3.0693018],\n",
      "       [3.0745206],\n",
      "       [2.7964168],\n",
      "       [1.0252098]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1177518],\n",
      "       [3.0485914],\n",
      "       [3.0394099],\n",
      "       [3.0566733],\n",
      "       [3.0622218],\n",
      "       [3.0680747],\n",
      "       [3.0734346],\n",
      "       [3.0783799],\n",
      "       [2.8581793],\n",
      "       [1.145826 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1269207],\n",
      "       [3.052183 ],\n",
      "       [3.0457556],\n",
      "       [3.0620792],\n",
      "       [3.0672548],\n",
      "       [3.0727808],\n",
      "       [3.077834 ],\n",
      "       [3.0824864],\n",
      "       [2.9108799],\n",
      "       [1.2670256]], dtype=float32)]\n",
      "prev_seq_out [array([[3.135752 ],\n",
      "       [3.0565302],\n",
      "       [3.052471 ],\n",
      "       [3.0677757],\n",
      "       [3.0725584],\n",
      "       [3.0777318],\n",
      "       [3.0824554],\n",
      "       [3.0867977],\n",
      "       [2.9549932],\n",
      "       [1.3895513]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1440735],\n",
      "       [3.0615373],\n",
      "       [3.059476 ],\n",
      "       [3.073701 ],\n",
      "       [3.0780742],\n",
      "       [3.0828748],\n",
      "       [3.0872502],\n",
      "       [3.0912678],\n",
      "       [2.991362 ],\n",
      "       [1.514187 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1517336],\n",
      "       [3.067101 ],\n",
      "       [3.066687 ],\n",
      "       [3.0797873],\n",
      "       [3.0837417],\n",
      "       [3.0881534],\n",
      "       [3.092167 ],\n",
      "       [3.0958495],\n",
      "       [3.0210216],\n",
      "       [1.6416022]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1585977],\n",
      "       [3.073114 ],\n",
      "       [3.0740166],\n",
      "       [3.0859652],\n",
      "       [3.0894964],\n",
      "       [3.0935082],\n",
      "       [3.097151 ],\n",
      "       [3.100492 ],\n",
      "       [3.0450501],\n",
      "       [1.7721914]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1645465],\n",
      "       [3.0794585],\n",
      "       [3.0813713],\n",
      "       [3.0921588],\n",
      "       [3.095269 ],\n",
      "       [3.098876 ],\n",
      "       [3.1021447],\n",
      "       [3.1051426],\n",
      "       [3.0644674],\n",
      "       [1.9058987]], dtype=float32)]\n",
      "prev_seq_out [array([[3.169471 ],\n",
      "       [3.086009 ],\n",
      "       [3.0886533],\n",
      "       [3.0982864],\n",
      "       [3.100985 ],\n",
      "       [3.1041892],\n",
      "       [3.107087 ],\n",
      "       [3.1097438],\n",
      "       [3.0801718],\n",
      "       [2.0420341]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1732805],\n",
      "       [3.0926287],\n",
      "       [3.09576  ],\n",
      "       [3.1042624],\n",
      "       [3.1065652],\n",
      "       [3.109375 ],\n",
      "       [3.11191  ],\n",
      "       [3.114235 ],\n",
      "       [3.0929143],\n",
      "       [2.1791165]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1759093],\n",
      "       [3.099175 ],\n",
      "       [3.1025853],\n",
      "       [3.109998 ],\n",
      "       [3.1119277],\n",
      "       [3.1143584],\n",
      "       [3.116546 ],\n",
      "       [3.1185527],\n",
      "       [3.103299 ],\n",
      "       [2.3148065]], dtype=float32)]\n",
      "prev_seq_out [array([[3.177335 ],\n",
      "       [3.1055036],\n",
      "       [3.1090264],\n",
      "       [3.1154053],\n",
      "       [3.1169925],\n",
      "       [3.1190653],\n",
      "       [3.120926 ],\n",
      "       [3.1226337],\n",
      "       [3.1117966],\n",
      "       [2.4460256]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1775925],\n",
      "       [3.1114829],\n",
      "       [3.1149905],\n",
      "       [3.1204062],\n",
      "       [3.121684 ],\n",
      "       [3.1234274],\n",
      "       [3.1249866],\n",
      "       [3.12642  ],\n",
      "       [3.118769 ],\n",
      "       [2.5693083]], dtype=float32)]\n",
      "prev_seq_out [array([[3.176787 ],\n",
      "       [3.117002 ],\n",
      "       [3.1204014],\n",
      "       [3.1249359],\n",
      "       [3.1259434],\n",
      "       [3.127389 ],\n",
      "       [3.1286776],\n",
      "       [3.1298625],\n",
      "       [3.1244917],\n",
      "       [2.681363 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1750908],\n",
      "       [3.1219814],\n",
      "       [3.1252086],\n",
      "       [3.1289532],\n",
      "       [3.12973  ],\n",
      "       [3.1309125],\n",
      "       [3.131962 ],\n",
      "       [3.1329286],\n",
      "       [3.1291769],\n",
      "       [2.7796757]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1727293],\n",
      "       [3.1263773],\n",
      "       [3.129391 ],\n",
      "       [3.1324415],\n",
      "       [3.1330264],\n",
      "       [3.133982 ],\n",
      "       [3.1348257],\n",
      "       [3.135603 ],\n",
      "       [3.1329932],\n",
      "       [2.862937 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1699495],\n",
      "       [3.1301818],\n",
      "       [3.132957 ],\n",
      "       [3.1354089],\n",
      "       [3.135839 ],\n",
      "       [3.1366024],\n",
      "       [3.1372724],\n",
      "       [3.1378896],\n",
      "       [3.1360807],\n",
      "       [2.9311466]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1669896],\n",
      "       [3.1334174],\n",
      "       [3.1359398],\n",
      "       [3.1378863],\n",
      "       [3.1381946],\n",
      "       [3.1387975],\n",
      "       [3.1393237],\n",
      "       [3.1398087],\n",
      "       [3.138558 ],\n",
      "       [2.9853961]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1640508],\n",
      "       [3.1361275],\n",
      "       [3.1383922],\n",
      "       [3.1399179],\n",
      "       [3.1401327],\n",
      "       [3.1406054],\n",
      "       [3.1410146],\n",
      "       [3.1413913],\n",
      "       [3.1405287],\n",
      "       [3.0274723]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1612816],\n",
      "       [3.1383677],\n",
      "       [3.1403766],\n",
      "       [3.1415586],\n",
      "       [3.1417038],\n",
      "       [3.1420715],\n",
      "       [3.1423864],\n",
      "       [3.142677 ],\n",
      "       [3.1420834],\n",
      "       [3.0594442]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_seq_out [array([[3.1587775],\n",
      "       [3.140199 ],\n",
      "       [3.1419601],\n",
      "       [3.142866 ],\n",
      "       [3.14296  ],\n",
      "       [3.143245 ],\n",
      "       [3.1434848],\n",
      "       [3.1437075],\n",
      "       [3.1432993],\n",
      "       [3.083348 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1565864],\n",
      "       [3.1416826],\n",
      "       [3.1432085],\n",
      "       [3.1438951],\n",
      "       [3.1439536],\n",
      "       [3.1441727],\n",
      "       [3.1443543],\n",
      "       [3.144524 ],\n",
      "       [3.1442435],\n",
      "       [3.100999 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1547184],\n",
      "       [3.1428742],\n",
      "       [3.1441824],\n",
      "       [3.1446972],\n",
      "       [3.1447313],\n",
      "       [3.144899 ],\n",
      "       [3.1450357],\n",
      "       [3.1451638],\n",
      "       [3.1449716],\n",
      "       [3.1139104]], dtype=float32)]\n",
      "prev_seq_out [array([[3.153161 ],\n",
      "       [3.1438258],\n",
      "       [3.1449347],\n",
      "       [3.1453173],\n",
      "       [3.1453345],\n",
      "       [3.1454625],\n",
      "       [3.145565 ],\n",
      "       [3.1456614],\n",
      "       [3.145529 ],\n",
      "       [3.123289 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1518853],\n",
      "       [3.1445804],\n",
      "       [3.1455116],\n",
      "       [3.1457925],\n",
      "       [3.1457992],\n",
      "       [3.1458962],\n",
      "       [3.1459734],\n",
      "       [3.146045 ],\n",
      "       [3.1459544],\n",
      "       [3.1300664]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1508553],\n",
      "       [3.1451752],\n",
      "       [3.1459503],\n",
      "       [3.1461546],\n",
      "       [3.1461544],\n",
      "       [3.1462283],\n",
      "       [3.146286 ],\n",
      "       [3.1463385],\n",
      "       [3.146277 ],\n",
      "       [3.1349459]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1500344],\n",
      "       [3.1456425],\n",
      "       [3.146282 ],\n",
      "       [3.1464288],\n",
      "       [3.1464252],\n",
      "       [3.1464808],\n",
      "       [3.1465237],\n",
      "       [3.1465628],\n",
      "       [3.1465209],\n",
      "       [3.1384492]], dtype=float32)]\n",
      "prev_seq_out [array([[3.149387 ],\n",
      "       [3.1460078],\n",
      "       [3.1465313],\n",
      "       [3.1466353],\n",
      "       [3.1466305],\n",
      "       [3.1466722],\n",
      "       [3.1467042],\n",
      "       [3.1467335],\n",
      "       [3.1467044],\n",
      "       [3.140959 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1488805],\n",
      "       [3.1462924],\n",
      "       [3.1467178],\n",
      "       [3.1467905],\n",
      "       [3.1467855],\n",
      "       [3.146817 ],\n",
      "       [3.1468403],\n",
      "       [3.146862 ],\n",
      "       [3.146842 ],\n",
      "       [3.142755 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1484878],\n",
      "       [3.1465132],\n",
      "       [3.146857 ],\n",
      "       [3.1469069],\n",
      "       [3.1469016],\n",
      "       [3.1469254],\n",
      "       [3.1469424],\n",
      "       [3.1469588],\n",
      "       [3.146945 ],\n",
      "       [3.1440392]], dtype=float32)]\n",
      "prev_seq_out [array([[3.148185 ],\n",
      "       [3.146684 ],\n",
      "       [3.1469603],\n",
      "       [3.1469936],\n",
      "       [3.1469886],\n",
      "       [3.1470065],\n",
      "       [3.1470194],\n",
      "       [3.1470315],\n",
      "       [3.1470213],\n",
      "       [3.1449566]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1479535],\n",
      "       [3.1468155],\n",
      "       [3.1470363],\n",
      "       [3.147058 ],\n",
      "       [3.1470537],\n",
      "       [3.147067 ],\n",
      "       [3.1470766],\n",
      "       [3.1470857],\n",
      "       [3.1470785],\n",
      "       [3.1456113]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1477766],\n",
      "       [3.1469166],\n",
      "       [3.147092 ],\n",
      "       [3.1471064],\n",
      "       [3.147102 ],\n",
      "       [3.1471121],\n",
      "       [3.147119 ],\n",
      "       [3.1471262],\n",
      "       [3.147121 ],\n",
      "       [3.1460788]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1476429],\n",
      "       [3.146994 ],\n",
      "       [3.1471334],\n",
      "       [3.147142 ],\n",
      "       [3.1471384],\n",
      "       [3.1471455],\n",
      "       [3.147151 ],\n",
      "       [3.147156 ],\n",
      "       [3.1471527],\n",
      "       [3.1464117]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1475413],\n",
      "       [3.1470537],\n",
      "       [3.1471634],\n",
      "       [3.147168 ],\n",
      "       [3.147165 ],\n",
      "       [3.1471705],\n",
      "       [3.1471748],\n",
      "       [3.147178 ],\n",
      "       [3.1471758],\n",
      "       [3.1466496]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1474652],\n",
      "       [3.147099 ],\n",
      "       [3.1471853],\n",
      "       [3.1471872],\n",
      "       [3.1471848],\n",
      "       [3.1471887],\n",
      "       [3.1471922],\n",
      "       [3.1471944],\n",
      "       [3.147193 ],\n",
      "       [3.1468194]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147408 ],\n",
      "       [3.1471334],\n",
      "       [3.1472013],\n",
      "       [3.147201 ],\n",
      "       [3.1471996],\n",
      "       [3.147202 ],\n",
      "       [3.1472056],\n",
      "       [3.147207 ],\n",
      "       [3.1472056],\n",
      "       [3.1469405]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1473649],\n",
      "       [3.1471598],\n",
      "       [3.1472123],\n",
      "       [3.1472116],\n",
      "       [3.1472108],\n",
      "       [3.147212 ],\n",
      "       [3.147215 ],\n",
      "       [3.1472158],\n",
      "       [3.147215 ],\n",
      "       [3.1470263]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147333 ],\n",
      "       [3.1471796],\n",
      "       [3.1472201],\n",
      "       [3.1472194],\n",
      "       [3.1472187],\n",
      "       [3.1472194],\n",
      "       [3.1472218],\n",
      "       [3.1472223],\n",
      "       [3.147222 ],\n",
      "       [3.147088 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1473088],\n",
      "       [3.1471946],\n",
      "       [3.1472263],\n",
      "       [3.1472254],\n",
      "       [3.1472247],\n",
      "       [3.1472251],\n",
      "       [3.1472268],\n",
      "       [3.1472268],\n",
      "       [3.1472268],\n",
      "       [3.1471317]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147291 ],\n",
      "       [3.147206 ],\n",
      "       [3.1472306],\n",
      "       [3.1472292],\n",
      "       [3.147229 ],\n",
      "       [3.1472292],\n",
      "       [3.1472301],\n",
      "       [3.1472306],\n",
      "       [3.1472306],\n",
      "       [3.147163 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472778],\n",
      "       [3.1472154],\n",
      "       [3.1472335],\n",
      "       [3.1472323],\n",
      "       [3.1472323],\n",
      "       [3.1472325],\n",
      "       [3.1472335],\n",
      "       [3.1472332],\n",
      "       [3.1472335],\n",
      "       [3.1471853]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147268 ],\n",
      "       [3.1472216],\n",
      "       [3.1472359],\n",
      "       [3.1472344],\n",
      "       [3.1472347],\n",
      "       [3.1472347],\n",
      "       [3.1472354],\n",
      "       [3.1472354],\n",
      "       [3.1472354],\n",
      "       [3.1472013]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147261 ],\n",
      "       [3.1472268],\n",
      "       [3.147237 ],\n",
      "       [3.1472363],\n",
      "       [3.147236 ],\n",
      "       [3.1472359],\n",
      "       [3.1472373],\n",
      "       [3.1472373],\n",
      "       [3.147237 ],\n",
      "       [3.1472125]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472554],\n",
      "       [3.1472304],\n",
      "       [3.1472378],\n",
      "       [3.1472378],\n",
      "       [3.1472373],\n",
      "       [3.147237 ],\n",
      "       [3.1472385],\n",
      "       [3.147238 ],\n",
      "       [3.147238 ],\n",
      "       [3.1472208]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472518],\n",
      "       [3.147233 ],\n",
      "       [3.147239 ],\n",
      "       [3.1472392],\n",
      "       [3.147238 ],\n",
      "       [3.1472383],\n",
      "       [3.1472394],\n",
      "       [3.1472387],\n",
      "       [3.1472387],\n",
      "       [3.1472263]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147249 ],\n",
      "       [3.1472347],\n",
      "       [3.1472394],\n",
      "       [3.1472394],\n",
      "       [3.1472387],\n",
      "       [3.1472392],\n",
      "       [3.14724  ],\n",
      "       [3.1472392],\n",
      "       [3.1472392],\n",
      "       [3.1472304]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472466],\n",
      "       [3.1472359],\n",
      "       [3.1472404],\n",
      "       [3.14724  ],\n",
      "       [3.1472392],\n",
      "       [3.1472394],\n",
      "       [3.1472404],\n",
      "       [3.14724  ],\n",
      "       [3.14724  ],\n",
      "       [3.1472332]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147245 ],\n",
      "       [3.1472375],\n",
      "       [3.1472406],\n",
      "       [3.1472404],\n",
      "       [3.14724  ],\n",
      "       [3.1472402],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472402],\n",
      "       [3.1472354]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147244 ],\n",
      "       [3.1472383],\n",
      "       [3.1472406],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.147237 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472433],\n",
      "       [3.1472387],\n",
      "       [3.1472406],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.147238 ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472428],\n",
      "       [3.1472394],\n",
      "       [3.1472406],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472404],\n",
      "       [3.1472387]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147242 ],\n",
      "       [3.14724  ],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472392]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472416],\n",
      "       [3.1472402],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472394]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472414],\n",
      "       [3.1472404],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.14724  ]], dtype=float32)]\n",
      "prev_seq_out [array([[3.147241 ],\n",
      "       [3.1472404],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472402]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_seq_out [array([[3.147241 ],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472409],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n",
      "prev_seq_out [array([[3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406],\n",
      "       [3.1472406]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# 预测 300 可用\n",
    "%matplotlib qt\n",
    "gen_length = 500\n",
    "prime_word = '1'\n",
    "loaded_graph = tf.Graph()\n",
    "tf.reset_default_graph()\n",
    "seq, res = get_batch_boston()\n",
    "# BATCH_SIZE  = 1 \n",
    "#改变 cell 的尺寸 和 输入数据的尺寸一致\n",
    "model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, 1)\n",
    "saver = tf.train.Saver()\n",
    "fig = plt.figure(figsize=(20, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "# train_y1 = train_y[190:490]\n",
    "# train_y2 = train_y[0:300]\n",
    "# train_y3 = train_y[0:506]\n",
    "line5, = axes.plot(train_y.flatten(), 'y', label='实际5')\n",
    "plt.ion()\n",
    "plt.show()\n",
    "print('seq', seq.shape)\n",
    "with tf.Session() as sess:\n",
    "    # 加载保存过的session\n",
    "    #     loader = tf.train.import_meta_graph(save_dir + '.meta')\n",
    "    saver.restore(sess, './bst_save/ckpt/bst')\n",
    "    #取训练集的最后一行，作为开始\n",
    "#     prev_seq=train_x[-1]\n",
    "#     prev_seq = seq[-1]\n",
    "    prev_seq = np.array([seq.reshape(-1,10,1)[0].tolist()])\n",
    "#      可用\n",
    "#     prev_seq = np.array([train_x_np[50].tolist()])\n",
    "    print('prev_seq', prev_seq.shape)\n",
    "    predict=[]\n",
    "    for i in range(200):\n",
    "#         print('prev_seq_in',prev_seq)\n",
    "        if i == 0:\n",
    "#             print('if')\n",
    "            feed_dict = {\n",
    "                # create initial state\n",
    "                model.xs: prev_seq\n",
    "            }\n",
    "        else:\n",
    "#             print('else')\n",
    "            feed_dict = {\n",
    "                model.xs: prev_seq,\n",
    "                # use last state as the initial state for this run\n",
    "                model.cell_init_state: state \n",
    "            }\n",
    "        state, next_seq = sess.run([model.cell_final_state, model.pred],\n",
    "                               feed_dict=feed_dict)\n",
    "#         print('next_seq',next_seq.shape)\n",
    "#         print('next_seq',next_seq[-1])\n",
    "#         print(type(predict))\n",
    "#       下次的训练数据都是老一代的1-X加预测值的最后一位，所以数据可视化的时候，只需要展出最后更新那一位就可以了\n",
    "#       梯度消失\n",
    "        predict.append(next_seq[-1])\n",
    "#         predict = np.append(predict,next_seq)\n",
    "#         print('prev_seq',prev_seq.reshape([-1]).shape\n",
    "#         print('prev_seq',prev_seq.shape)\n",
    "#         print('next_seq',next_seq.shape)\n",
    "#         print('next_seq',next_seq[-1].shape)\n",
    "        print('prev_seq_out',prev_seq)\n",
    "#        丢弃首位，插入末位，输入的数据保持0-8位的一致性，形成连续\n",
    "#         prev_seq = np.append(prev_seq.reshape(TIME_STEPS)[1:],next_seq.reshape(TIME_STEPS)[-1]).reshape(1,10,1)\n",
    "#         prev_seq = prev_seq.reshape(1,10,1)\n",
    "\n",
    "#         print('prev_seq[1:]',prev_seq[1:])\n",
    "#        全新输入，梯度爆炸\n",
    "        prev_seq = [next_seq]\n",
    "#         prev_seq = np.vstack((prev_seq[1:],[next_seq]))\n",
    "\n",
    "        line1, = axes.plot(predict, 'b--', label='rnn计算结果' + str(i))\n",
    "        axes.grid()\n",
    "        fig.tight_layout()\n",
    "        plt.legend(handles=[line1, line5])\n",
    "        plt.title('递归神经网络')\n",
    "        plt.pause(0.01)\n",
    "\n",
    "    BATCH_START = 0\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 预测 10\n",
    "%matplotlib qt\n",
    "gen_length = 500\n",
    "prime_word = '1'\n",
    "loaded_graph = tf.Graph()\n",
    "tf.reset_default_graph()\n",
    "seq, res = get_batch_boston()\n",
    "# BATCH_SIZE  = 1 \n",
    "#改变 cell 的尺寸 和 输入数据的尺寸一致\n",
    "model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, 1)\n",
    "saver = tf.train.Saver()\n",
    "fig = plt.figure(figsize=(20, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "# train_y1 = train_y[190:490]\n",
    "# train_y2 = train_y[0:300]\n",
    "# train_y3 = train_y[0:506]\n",
    "line5, = axes.plot(train_y.flatten(), 'y', label='实际5')\n",
    "plt.ion()\n",
    "plt.show()\n",
    "print('seq', seq.shape)\n",
    "with tf.Session() as sess:\n",
    "    # 加载保存过的session\n",
    "    #     loader = tf.train.import_meta_graph(save_dir + '.meta')\n",
    "    saver.restore(sess, './bst_save/ckpt/bst')\n",
    "    #取训练集的最后一行，作为开始\n",
    "#     prev_seq=train_x[-1]\n",
    "#     prev_seq = seq[-1]\n",
    "    prev_seq = np.array([train_x_np[0][0].tolist()])\n",
    "    print('prev_seq', prev_seq.shape)\n",
    "    predict=[]\n",
    "    for i in range(20):\n",
    "        if i == 0:\n",
    "#             print('if')\n",
    "            feed_dict = {\n",
    "                # create initial state\n",
    "                model.xs: prev_seq\n",
    "            }\n",
    "        else:\n",
    "#             print('else')\n",
    "            feed_dict = {\n",
    "                model.xs: prev_seq,\n",
    "                # use last state as the initial state for this run\n",
    "                model.cell_init_state: state \n",
    "            }\n",
    "        state, next_seq = sess.run([model.cell_final_state, model.pred],\n",
    "                               feed_dict=feed_dict)\n",
    "#         print('next_seq',next_seq.shape)\n",
    "#         print('next_seq',next_seq[-1])\n",
    "#         print(type(predict))\n",
    "        predict.append(next_seq[-1])\n",
    "        \n",
    "#         print('prev_seq',prev_seq.reshape([-1]).shape\n",
    "#         print('prev_seq',prev_seq.shape)\n",
    "#         print('next_seq',next_seq.shape)\n",
    "#         print('next_seq',next_seq[-1].shape)\n",
    "        prev_seq = np.vstack((prev_seq[1:],[next_seq]))\n",
    "\n",
    "        line1, = axes.plot(predict, 'b--', label='rnn计算结果' + str(i))\n",
    "        axes.grid()\n",
    "        fig.tight_layout()\n",
    "        plt.legend(handles=[line1, line5])\n",
    "        plt.title('递归神经网络')\n",
    "        plt.pause(0.5)\n",
    "\n",
    "    BATCH_START = 0\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:26:15.855897Z",
     "start_time": "2018-12-03T03:26:15.071890Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间段= 170 470\n",
      "x_part1= (300, 13)\n",
      "<class 'numpy.ndarray'>\n",
      "(300, 1)\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib qt\n",
    "gen_length = 500\n",
    "prime_word = '1'\n",
    "loaded_graph = tf.Graph()\n",
    "tf.reset_default_graph()\n",
    "seq, res = get_batch_boston()\n",
    "model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, BATCH_SIZE)\n",
    "saver = tf.train.Saver()\n",
    "fig = plt.figure(figsize=(20, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "train_y1 = train_y[190:490]\n",
    "train_y2 = train_y[0:300]\n",
    "train_y3 = train_y\n",
    "# train_y1 = train_y[190:300]\n",
    "# train_y2 = train_y[190:300]\n",
    "\n",
    "print(type(train_y1))\n",
    "print(train_y1.shape)\n",
    "# train_y1.flatten()[-100:]\n",
    "# line3, = axes.plot(train_y1.flatten(), 'r', label='实际1>190')\n",
    "\n",
    "line5, = axes.plot(train_y3.flatten(), 'y', label='实际3')\n",
    "line4, = axes.plot(train_y2.flatten(), 'g', label='实际2>0')\n",
    "plt.legend(handles=[line4,line3])\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T02:37:00.527203Z",
     "start_time": "2018-12-10T02:37:00.511124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 30, 10, 1)\n",
      "(291, 10, 1)\n",
      "[[ 0.17056941]\n",
      " [ 2.1514115 ]\n",
      " [ 2.82620386]\n",
      " [ 2.98946007]\n",
      " [ 0.00731319]\n",
      " [ 0.20322065]\n",
      " [-0.00357056]\n",
      " [ 0.20322065]\n",
      " [-0.27566425]\n",
      " [-0.09064054]]\n",
      "\n",
      "[[ 0.17056941]\n",
      " [ 2.1514115 ]\n",
      " [ 2.82620386]\n",
      " [ 2.98946007]\n",
      " [ 0.00731319]\n",
      " [ 0.20322065]\n",
      " [-0.00357056]\n",
      " [ 0.20322065]\n",
      " [-0.27566425]\n",
      " [-0.09064054]]\n"
     ]
    }
   ],
   "source": [
    "seq, res = get_batch_boston()\n",
    "print(seq.shape)\n",
    "print(train_x_np.shape)\n",
    "# print(seq.reshape(-1,10,1)[0])\n",
    "#0-29：0-290：0：10\n",
    "#30-59：1-291，31：11，32：21\n",
    "print(seq.reshape(-1,10,1)[50])\n",
    "print()\n",
    "# print(train_x_np[0])\n",
    "print(train_x_np[201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:35:58.191782Z",
     "start_time": "2018-12-03T02:35:58.184888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "[0 1 2 3 4 5]\n",
      "[4 5]\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(6).reshape(3,2)\n",
    "print(a)\n",
    "print(a.flatten())\n",
    "print(a.flatten()[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:34:24.975787Z",
     "start_time": "2018-12-03T03:34:24.477551Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(2,1,1)      # 分成两行一列，起始点为1\n",
    "plt.plot([0,1],[0,1])   # 设置xy轴范围\n",
    "\n",
    "plt.subplot(2,3,4)      # 分成两行三列，起始点位4\n",
    "plt.plot([0,1],[0,2])\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.plot([0,1],[0,3])\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.plot([0,1],[0,4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T01:25:33.073469Z",
     "start_time": "2018-12-06T01:25:33.049645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12 13]\n",
      " [14 15 16 17 18 19 20]\n",
      " [21 22 23 24 25 26 27]\n",
      " [28 29 30 31 32 33 34]\n",
      " [35 36 37 38 39 40 41]\n",
      " [42 43 44 45 46 47 48]\n",
      " [49 50 51 52 53 54 55]]\n",
      "[ 0  7 14 21 28 35 42 49]\n",
      "[-15.          80.66666667 176.33333333 272.         367.66666667\n",
      " 463.33333333 559.         654.66666667]\n",
      "a [[ 7  8  9 10 11 12 13]\n",
      " [14 15 16 17 18 19 20]\n",
      " [21 22 23 24 25 26 27]\n",
      " [28 29 30 31 32 33 34]\n",
      " [35 36 37 38 39 40 41]\n",
      " [42 43 44 45 46 47 48]\n",
      " [49 50 51 52 53 54 55]]\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(56).reshape(8,7)\n",
    "#X取前5行的前三列（从1计数）\n",
    "x=a[0:0+5,:3]\n",
    "#Y取前5行的第4列（从0计数），并行转列\n",
    "y=a[0:0+5,0,np.newaxis]\n",
    "z=a[:,0]\n",
    "print(a)\n",
    "print(z)\n",
    "zz =  (a[:,0] * 1000 / 60) - (a[:,4] + a[:,5] + a[:,6])\n",
    "print(zz)\n",
    "print('a',a[1:])\n",
    "# print(x.shape)\n",
    "# print(x)\n",
    "# print(y.shape)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T12:10:13.178812Z",
     "start_time": "2018-12-06T12:10:13.147758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 300\n",
      "1 301\n",
      "2 302\n",
      "3 303\n",
      "4 304\n",
      "5 305\n",
      "6 306\n",
      "7 307\n",
      "8 308\n",
      "9 309\n",
      "10 310\n",
      "11 311\n",
      "12 312\n",
      "13 313\n",
      "14 314\n",
      "15 315\n",
      "16 316\n",
      "17 317\n",
      "18 318\n",
      "19 319\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "train_x_list,train_y_list=[],[]\n",
    "for i in range(20):\n",
    "    x1=train_y[i:i+TIME_STEPS*BATCH_SIZE]\n",
    "    y1=train_y[i+1:i+TIME_STEPS*BATCH_SIZE+1]\n",
    "    x1=x1.reshape(30,10,-1)\n",
    "    y1=x1.reshape(30,10,-1)\n",
    "    train_x_list.append(x1.tolist())\n",
    "    train_y_list.append(y1.tolist()) \n",
    "    print(i,i+TIME_STEPS*BATCH_SIZE)\n",
    "print(len(train_x_list))\n",
    "print(len(train_y_list))\n",
    "train_x_np = np.array(train_x_list)\n",
    "train_y_np = np.array(train_y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T02:05:24.806127Z",
     "start_time": "2018-12-07T02:05:24.708648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "1 11\n",
      "2 12\n",
      "3 13\n",
      "4 14\n",
      "5 15\n",
      "6 16\n",
      "7 17\n",
      "8 18\n",
      "9 19\n",
      "10 20\n",
      "11 21\n",
      "12 22\n",
      "13 23\n",
      "14 24\n",
      "15 25\n",
      "16 26\n",
      "17 27\n",
      "18 28\n",
      "19 29\n",
      "20 30\n",
      "21 31\n",
      "22 32\n",
      "23 33\n",
      "24 34\n",
      "25 35\n",
      "26 36\n",
      "27 37\n",
      "28 38\n",
      "29 39\n",
      "30 40\n",
      "31 41\n",
      "32 42\n",
      "33 43\n",
      "34 44\n",
      "35 45\n",
      "36 46\n",
      "37 47\n",
      "38 48\n",
      "39 49\n",
      "40 50\n",
      "41 51\n",
      "42 52\n",
      "43 53\n",
      "44 54\n",
      "45 55\n",
      "46 56\n",
      "47 57\n",
      "48 58\n",
      "49 59\n",
      "50 60\n",
      "51 61\n",
      "52 62\n",
      "53 63\n",
      "54 64\n",
      "55 65\n",
      "56 66\n",
      "57 67\n",
      "58 68\n",
      "59 69\n",
      "60 70\n",
      "61 71\n",
      "62 72\n",
      "63 73\n",
      "64 74\n",
      "65 75\n",
      "66 76\n",
      "67 77\n",
      "68 78\n",
      "69 79\n",
      "70 80\n",
      "71 81\n",
      "72 82\n",
      "73 83\n",
      "74 84\n",
      "75 85\n",
      "76 86\n",
      "77 87\n",
      "78 88\n",
      "79 89\n",
      "80 90\n",
      "81 91\n",
      "82 92\n",
      "83 93\n",
      "84 94\n",
      "85 95\n",
      "86 96\n",
      "87 97\n",
      "88 98\n",
      "89 99\n",
      "90 100\n",
      "91 101\n",
      "92 102\n",
      "93 103\n",
      "94 104\n",
      "95 105\n",
      "96 106\n",
      "97 107\n",
      "98 108\n",
      "99 109\n",
      "100 110\n",
      "101 111\n",
      "102 112\n",
      "103 113\n",
      "104 114\n",
      "105 115\n",
      "106 116\n",
      "107 117\n",
      "108 118\n",
      "109 119\n",
      "110 120\n",
      "111 121\n",
      "112 122\n",
      "113 123\n",
      "114 124\n",
      "115 125\n",
      "116 126\n",
      "117 127\n",
      "118 128\n",
      "119 129\n",
      "120 130\n",
      "121 131\n",
      "122 132\n",
      "123 133\n",
      "124 134\n",
      "125 135\n",
      "126 136\n",
      "127 137\n",
      "128 138\n",
      "129 139\n",
      "130 140\n",
      "131 141\n",
      "132 142\n",
      "133 143\n",
      "134 144\n",
      "135 145\n",
      "136 146\n",
      "137 147\n",
      "138 148\n",
      "139 149\n",
      "140 150\n",
      "141 151\n",
      "142 152\n",
      "143 153\n",
      "144 154\n",
      "145 155\n",
      "146 156\n",
      "147 157\n",
      "148 158\n",
      "149 159\n",
      "150 160\n",
      "151 161\n",
      "152 162\n",
      "153 163\n",
      "154 164\n",
      "155 165\n",
      "156 166\n",
      "157 167\n",
      "158 168\n",
      "159 169\n",
      "160 170\n",
      "161 171\n",
      "162 172\n",
      "163 173\n",
      "164 174\n",
      "165 175\n",
      "166 176\n",
      "167 177\n",
      "168 178\n",
      "169 179\n",
      "170 180\n",
      "171 181\n",
      "172 182\n",
      "173 183\n",
      "174 184\n",
      "175 185\n",
      "176 186\n",
      "177 187\n",
      "178 188\n",
      "179 189\n",
      "180 190\n",
      "181 191\n",
      "182 192\n",
      "183 193\n",
      "184 194\n",
      "185 195\n",
      "186 196\n",
      "187 197\n",
      "188 198\n",
      "189 199\n",
      "190 200\n",
      "191 201\n",
      "192 202\n",
      "193 203\n",
      "194 204\n",
      "195 205\n",
      "196 206\n",
      "197 207\n",
      "198 208\n",
      "199 209\n",
      "200 210\n",
      "201 211\n",
      "202 212\n",
      "203 213\n",
      "204 214\n",
      "205 215\n",
      "206 216\n",
      "207 217\n",
      "208 218\n",
      "209 219\n",
      "210 220\n",
      "211 221\n",
      "212 222\n",
      "213 223\n",
      "214 224\n",
      "215 225\n",
      "216 226\n",
      "217 227\n",
      "218 228\n",
      "219 229\n",
      "220 230\n",
      "221 231\n",
      "222 232\n",
      "223 233\n",
      "224 234\n",
      "225 235\n",
      "226 236\n",
      "227 237\n",
      "228 238\n",
      "229 239\n",
      "230 240\n",
      "231 241\n",
      "232 242\n",
      "233 243\n",
      "234 244\n",
      "235 245\n",
      "236 246\n",
      "237 247\n",
      "238 248\n",
      "239 249\n",
      "240 250\n",
      "241 251\n",
      "242 252\n",
      "243 253\n",
      "244 254\n",
      "245 255\n",
      "246 256\n",
      "247 257\n",
      "248 258\n",
      "249 259\n",
      "250 260\n",
      "251 261\n",
      "252 262\n",
      "253 263\n",
      "254 264\n",
      "255 265\n",
      "256 266\n",
      "257 267\n",
      "258 268\n",
      "259 269\n",
      "260 270\n",
      "261 271\n",
      "262 272\n",
      "263 273\n",
      "264 274\n",
      "265 275\n",
      "266 276\n",
      "267 277\n",
      "268 278\n",
      "269 279\n",
      "270 280\n",
      "271 281\n",
      "272 282\n",
      "273 283\n",
      "274 284\n",
      "275 285\n",
      "276 286\n",
      "277 287\n",
      "278 288\n",
      "279 289\n",
      "280 290\n",
      "281 291\n",
      "282 292\n",
      "283 293\n",
      "284 294\n",
      "285 295\n",
      "286 296\n",
      "287 297\n",
      "288 298\n",
      "289 299\n",
      "290 300\n"
     ]
    }
   ],
   "source": [
    "train_x_list,train_y_list=[],[]\n",
    "for i in range(len(train_y)-TIME_STEPS-205):\n",
    "    x1=train_y[i:i+TIME_STEPS]\n",
    "    y1=train_y[i+1:i+TIME_STEPS+1]\n",
    "#     x1=x1.reshape(30,10,-1)\n",
    "#     y1=x1.reshape(30,10,-1)\n",
    "    train_x_list.append(x1.tolist())\n",
    "    train_y_list.append(y1.tolist()) \n",
    "    print(i,i+TIME_STEPS)\n",
    "# print(len(train_x_list))\n",
    "# print(len(train_y_list))\n",
    "train_x_np = np.array(train_x_list)\n",
    "train_y_np = np.array(train_y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T02:22:01.217697Z",
     "start_time": "2018-12-07T02:22:01.191849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 10, 1)\n",
      "(21, 10, 1)\n",
      "b <class 'numpy.ndarray'>\n",
      "[[0.15968566]]\n",
      "len 301\n",
      "(291, 10, 1)\n",
      "(291, 10, 1)\n",
      "seq (10, 1)\n",
      "res (291, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "# print(train_x_np[0].shape)\n",
    "# print(train_x_np[0][0].shape)\n",
    "print(train_x_np.shape)\n",
    "print(train_x_np[270:300].shape)\n",
    "# print('a',train_x_np[0])\n",
    "print('b',type(train_x_np[np.newaxis][0][0]))\n",
    "[train_x_np[0][0].tolist()]\n",
    "\n",
    "print(np.array([train_x_np[0][0].tolist()]))\n",
    "print('len',len(train_x)-205)\n",
    "print(train_x_np.shape)\n",
    "print(train_y_np.shape)\n",
    "# print(y.shape)\n",
    "# print(train_y.shape)\n",
    "seq, res = get_batch_boston()\n",
    "print('seq',seq[-1].shape)\n",
    "print('res',res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T07:28:34.069103Z",
     "start_time": "2018-12-10T07:28:33.861737Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "line3, = axes.plot(train_y[19:-1], 'r', label='实际')\n",
    "plt.ion()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T07:29:14.115755Z",
     "start_time": "2018-12-10T07:29:13.928788Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "line4, = axes.plot(train_x[0:-1], 'b--', label='实际')\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T06:03:51.376422Z",
     "start_time": "2018-12-12T06:03:51.353604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 300\n"
     ]
    }
   ],
   "source": [
    "def get_batch_boston_original():\n",
    "    global train_x, train_y, BATCH_START, TIME_STEPS\n",
    "    BATCH_START = 0\n",
    "    # 每次都是拿300行，13列的数据，但是起始点根据 BATCH_START\n",
    "    x_part1 = train_x[BATCH_START:BATCH_START + TIME_STEPS * BATCH_SIZE]\n",
    "    y_part1 = train_y[BATCH_START:BATCH_START + TIME_STEPS * BATCH_SIZE]\n",
    "    print(BATCH_START,BATCH_START + TIME_STEPS * BATCH_SIZE)\n",
    "    # 时间段= 0 300\n",
    "    # x_part1= (300, 13)\n",
    "    # 时间段= 10 310\n",
    "    # x_part1= (300, 13)\n",
    "#     print('时间段=', BATCH_START, BATCH_START + TIME_STEPS * BATCH_SIZE)\n",
    "#     print('x_part1=', x_part1.shape)\n",
    "#     print(BATCH_SIZE, TIME_STEPS, INPUT_SIZE)\n",
    "    # 转成 30 10 13的形状\n",
    "    seq = x_part1.reshape((BATCH_SIZE, TIME_STEPS, INPUT_SIZE))\n",
    "    res = y_part1.reshape((BATCH_SIZE, TIME_STEPS, 1))\n",
    "\n",
    "    BATCH_START += TIME_STEPS\n",
    "\n",
    "    # returned seq, res and xs: shape (batch, step, input)\n",
    "    #np.newaxis 用来增加一个维度 变为三个维度，第三个维度将用来存上一批样本的状态\n",
    "    return [seq, res]\n",
    "\n",
    "st,rt = get_batch_boston_original()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_boston_single():\n",
    "    global train_x_list, train_y_list, BATCH_START, TIME_STEPS\n",
    "    train_x_list,train_y_list=[],[]\n",
    "    for i in range(1):\n",
    "        x1=train_y[i:i+TIME_STEPS*BATCH_SIZE]\n",
    "        y1=train_y[i+1:i+TIME_STEPS*BATCH_SIZE+1]\n",
    "        x1=x1.reshape(30,10,-1)\n",
    "        y1=y1.reshape(30,10,-1)\n",
    "        train_x_list.append(x1.tolist())\n",
    "        train_y_list.append(y1.tolist()) \n",
    "    train_x_np = np.array(train_x_list)\n",
    "    train_y_np = np.array(train_y_list)\n",
    "\n",
    "    seq = train_x_np\n",
    "    res = train_y_np\n",
    "    return [seq, res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T02:26:53.518594Z",
     "start_time": "2018-12-14T02:24:52.349373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq (20, 30, 10, 1)\n",
      "res (20, 30, 10, 1)\n",
      "0 cost:  5.2734\n",
      "10 cost:  4.1035\n",
      "20 cost:  4.0362\n",
      "30 cost:  4.551\n",
      "40 cost:  3.6982\n",
      "50 cost:  3.7115\n",
      "60 cost:  3.5777\n",
      "70 cost:  3.5367\n",
      "80 cost:  3.3439\n",
      "90 cost:  3.0244\n",
      "100 cost:  2.8598\n",
      "110 cost:  2.8282\n",
      "120 cost:  2.637\n",
      "130 cost:  2.6433\n",
      "140 cost:  2.6105\n",
      "150 cost:  2.5279\n",
      "160 cost:  2.519\n",
      "170 cost:  2.305\n",
      "180 cost:  2.3383\n",
      "190 cost:  2.0244\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "tf.reset_default_graph()\n",
    "if __name__ == '__main__':\n",
    "    # 设置画布初始属性和内容\n",
    "    \n",
    "#     fig = plt.figure(figsize=(20, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80\n",
    "#     axes = fig.add_subplot(1, 1, 1)\n",
    "#     line3, = axes.plot(train_y[19:-1], 'r', label='实际')\n",
    "#     plt.ion()\n",
    "#     plt.show()\n",
    "    \n",
    "    seq, res = get_batch_boston()\n",
    "    costlist = []\n",
    "    print('seq',seq.shape)\n",
    "    print('res',res.shape)\n",
    "    BATCH_SIZE  = 30\n",
    "    model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, BATCH_SIZE)\n",
    "    sess = tf.Session()\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"logs\", sess.graph)\n",
    "    # tf.initialize_all_variables() no long valid from\n",
    "    # 2017-03-02 if using tensorflow >= 0.12\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # relocate to the local dir and run this line to view it on Chrome (http://0.0.0.0:6006/):\n",
    "    # $ tensorboard --logdir='logs'\n",
    "    for j in range(200):  #训练200次\n",
    "        pred_res = None\n",
    "        # 300\n",
    "        seq, res = get_batch_boston()\n",
    "#         print('seq',seq.shape)\n",
    "#        用于300\n",
    "        for i in range(20):\n",
    "            if i == 0:\n",
    "#                 print('if')\n",
    "                feed_dict = {\n",
    "                    model.xs: seq[i],\n",
    "                    model.ys: res[i],\n",
    "                    # create initial state\n",
    "                }\n",
    "            else:\n",
    "#                 print('else')\n",
    "                feed_dict = {\n",
    "                    model.xs: seq[i],\n",
    "                    model.ys: res[i],\n",
    "                    model.cell_init_state:\n",
    "                    state  # use last state as the initial state for this run\n",
    "                }\n",
    "#             print('se',seq[start:end].shape)\n",
    "#             start += TIME_STEPS\n",
    "#             print('start',type(start))\n",
    "#             end=start+BATCH_SIZE\n",
    "\n",
    "#         10\n",
    "#         step=0\n",
    "#         start=0\n",
    "#         end=start+BATCH_SIZE\n",
    "#         #每个内循环是100次，数据是0-60，60-120，120-180，递增\n",
    "#         while(end<len(train_x)-206):\n",
    "#             print()\n",
    "#             if start == 0:\n",
    "# #                 print('if')\n",
    "#                 feed_dict = {\n",
    "#                     model.xs: seq[start:end],\n",
    "#                     model.ys: res[start:end],\n",
    "#                     # create initial state\n",
    "#                 }\n",
    "#             else:\n",
    "# #                 print('else')\n",
    "#                 feed_dict = {\n",
    "#                     model.xs: seq[start:end],\n",
    "#                     model.ys: res[start:end],\n",
    "#                     model.cell_init_state:\n",
    "#                     state  # use last state as the initial state for this run\n",
    "#                 }\n",
    "#             print('start,end,step',start,end,step,',seq',seq[start:end].shape)\n",
    "#             start+=BATCH_SIZE\n",
    "#             end=start+BATCH_SIZE\n",
    "#             #每10步保存一次参数\n",
    "#             if step%10==0:\n",
    "#                 print(i,step,cost)\n",
    "#             step+=1\n",
    "\n",
    "            \n",
    "            _, cost, state, pred = sess.run([\n",
    "                model.train_op, model.cost, model.cell_final_state, model.pred\n",
    "            ],feed_dict=feed_dict)\n",
    "            pred_res = pred\n",
    "            \n",
    "\n",
    "\n",
    "            result = sess.run(merged, feed_dict)\n",
    "            writer.add_summary(result, i)\n",
    "        if(j % 10 ==0):\n",
    "            print('{0} cost: '.format(j), round(cost, 4))\n",
    "        BATCH_START = 0  #从头再来一遍\n",
    "#         try:\n",
    "#             axes.lines.remove(line1)\n",
    "#             axes.lines.remove(line_c)\n",
    "#         except Exception:\n",
    "#             pass\n",
    "        \n",
    "#         costlist.append(cost)\n",
    "#         line_c, = axes.plot(costlist,'y',label='cost')\n",
    "#         handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        # 返回是, 是一个Line2D的对象，无逗号是一个包含了Line2D的数组\n",
    "#         line1, = axes.plot(\n",
    "#             range(100), pred.flatten()[-100:], 'b--', label='rnn计算结果 '+str(j))\n",
    "#         line1, = axes.plot(pred.flatten(), 'b--', label='rnn计算结果 '+str(j))\n",
    "#         axes.grid()\n",
    "#         fig.tight_layout()\n",
    "#         plt.legend(handles=[line1,line3])\n",
    "#         plt.title('递归神经网络')\n",
    "#         plt.pause(0.01)\n",
    "#     plt.ioff()\n",
    "#     plt.show()\n",
    "    \n",
    "    # 保存模型\n",
    "#     saver = tf.train.Saver()\n",
    "#     saver.save(sess, save_dir,)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

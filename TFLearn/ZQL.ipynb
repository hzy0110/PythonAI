{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:20.528365Z",
     "start_time": "2019-01-06T14:15:13.271568Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# import seaborn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:20.585070Z",
     "start_time": "2019-01-06T14:15:20.530766Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_table('../data/zhengqi_train.txt', low_memory=False, dtype=float)\n",
    "df_test = pd.read_table('../data/zhengqi_test.txt', low_memory=False, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:20.595080Z",
     "start_time": "2019-01-06T14:15:20.588013Z"
    }
   },
   "outputs": [],
   "source": [
    "df_x_train_all = df_train.drop(['target'],axis=1)\n",
    "df_y_train_all = df_train['target']\n",
    "all_data = pd.concat([df_x_train_all,df_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:20.600744Z",
     "start_time": "2019-01-06T14:15:20.598221Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:20.605996Z",
     "start_time": "2019-01-06T14:15:20.603369Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:20.610243Z",
     "start_time": "2019-01-06T14:15:20.608117Z"
    }
   },
   "outputs": [],
   "source": [
    "# for col in all_data.columns:\n",
    "#     seaborn.distplot(df_x_train_all[col])\n",
    "#     seaborn.distplot(df_test[col])\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:20.619853Z",
     "start_time": "2019-01-06T14:15:20.612700Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_data.drop(['V5','V17','V28','V22','V11','V9'],axis=1,inplace=True)\n",
    "\n",
    "df_x_train_all.drop(['V5','V17','V28','V22','V11','V9'],axis=1,inplace=True)\n",
    "df_test.drop(['V5','V17','V28','V22','V11','V9'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:20.630903Z",
     "start_time": "2019-01-06T14:15:20.622941Z"
    }
   },
   "outputs": [],
   "source": [
    "#数据标准化\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_minmax = pd.DataFrame(min_max_scaler.fit_transform(df_x_train_all),columns=df_x_train_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:24.017006Z",
     "start_time": "2019-01-06T14:15:24.014672Z"
    }
   },
   "outputs": [],
   "source": [
    "#针对特征['V0','V1','V6','V30']做数据变换，使得数据符合正态分布\n",
    "\n",
    "# import math\n",
    "\n",
    "# data_minmax['V0'] = data_minmax['V0'].apply(lambda x:math.exp(x))\n",
    "# data_minmax['V1'] = data_minmax['V1'].apply(lambda x:math.exp(x))\n",
    "# data_minmax['V6'] = data_minmax['V6'].apply(lambda x:math.exp(x))\n",
    "# data_minmax['V30'] = np.log1p(data_minmax['V30'])\n",
    "# #train['exp'] = train['target'].apply(lambda x:math.pow(1.5,x)+10)\n",
    "\n",
    "# X_scaled = pd.DataFrame(preprocessing.scale(data_minmax),columns = data_minmax.columns)\n",
    "# train_x = X_scaled.ix[0:len(df_train)-1]\n",
    "# test = X_scaled.ix[len(df_train):]\n",
    "\n",
    "# Y=df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:15:24.715985Z",
     "start_time": "2019-01-06T14:15:24.706245Z"
    }
   },
   "outputs": [],
   "source": [
    "#特征选择\n",
    "\n",
    "#方差\n",
    "threshold = 0.85                  \n",
    "vt = VarianceThreshold().fit(df_x_train_all)\n",
    "# Find feature names\n",
    "feat_var_threshold = df_x_train_all.columns[vt.variances_ > threshold * (1-threshold)]\n",
    "# print(feat_var_threshold)\n",
    "# print(vt.variances_)\n",
    "df_x_train_all = df_x_train_all[feat_var_threshold]\n",
    "df_test = df_test[feat_var_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:14:18.673379Z",
     "start_time": "2019-01-06T14:14:18.633138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['V0', 'V1', 'V2', 'V3', 'V4', 'V6', 'V7', 'V8', 'V10', 'V12', 'V13',\n",
      "       'V16', 'V20', 'V23', 'V24', 'V31', 'V36', 'V37'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V16</th>\n",
       "      <th>V20</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V31</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-1.812</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-1.707</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>-2.608</td>\n",
       "      <td>-3.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-1.566</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>1.109</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.013</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-1.367</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.874</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-0.618</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.733</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.599</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>-2.086</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.352</td>\n",
       "      <td>1.435</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-1.073</td>\n",
       "      <td>-2.086</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      V0     V1     V2     V3     V4     V6     V7     V8    V10    V12  \\\n",
       "0  0.566  0.016 -0.143  0.407  0.452 -1.812 -2.360 -0.436 -0.940 -0.073   \n",
       "1  0.968  0.437  0.066  0.566  0.194 -1.566 -2.360  0.332  0.188 -0.134   \n",
       "2  1.013  0.568  0.235  0.370  0.112 -1.367 -2.360  0.396  0.874 -0.072   \n",
       "3  0.733  0.368  0.283  0.165  0.599 -1.200 -2.086  0.403  0.011 -0.014   \n",
       "4  0.684  0.638  0.260  0.209  0.337 -1.073 -2.086  0.314 -0.251  0.199   \n",
       "\n",
       "     V13    V16    V20    V23    V24    V31    V36    V37  \n",
       "0  0.550 -1.707  0.610  0.356  0.800 -0.615 -2.608 -3.508  \n",
       "1  1.109 -0.977  0.588  0.357  0.801  0.032 -0.335 -0.730  \n",
       "2  0.767 -0.618  0.576  0.355  0.961  0.277  0.765 -0.589  \n",
       "3  0.769 -0.429  0.272  0.352  1.435  0.279  0.333 -0.112  \n",
       "4 -0.349 -0.391  0.106  0.352  0.881  0.328 -0.280 -0.028  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #单变量\n",
    "# X_scored = SelectKBest(score_func=f_regression, k='all').fit(df_x_train_all, df_y_train_all)\n",
    "# feature_scoring = pd.DataFrame({\n",
    "#         'feature': df_x_train_all.columns,\n",
    "#         'score': X_scored.scores_\n",
    "#     })\n",
    "\n",
    "# # print(feature_scoring)\n",
    "# head_feature_num = 18\n",
    "# feat_scored_headnum = feature_scoring.sort_values('score', ascending=False).head(head_feature_num)['feature']\n",
    "# # print(feat_scored_headnum)\n",
    "\n",
    "# a = df_x_train_all.columns[df_x_train_all.columns.isin(feat_scored_headnum)]\n",
    "# print(a)\n",
    "# df_x_train_all = df_x_train_all[a]\n",
    "# df_x_train_all.head()\n",
    "# # train_x_head = df_x_train_all[df_x_train_all.columns[df_x_train_all.columns.isin(feat_scored_headnum)]]\n",
    "# # X_scaled = pd.DataFrame(preprocessing.scale(df_x_train_all),columns = df_x_train_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:16:59.303829Z",
     "start_time": "2019-01-06T14:16:59.299787Z"
    }
   },
   "outputs": [],
   "source": [
    "df_x_train_all = df_x_train_all[['V0', 'V1', 'V2', 'V3', 'V4', 'V6', 'V7', 'V8',\n",
    "                                'V10', 'V12', 'V13', 'V16', 'V20', 'V23',\n",
    "                                'V24', 'V31', 'V36', 'V37']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-06T13:43:46.177Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(\n",
    "#     df_x_train_all, df_y_train_all, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:17:02.934188Z",
     "start_time": "2019-01-06T14:17:02.724555Z"
    }
   },
   "outputs": [],
   "source": [
    "#回归\n",
    "input_size = df_x_train_all.shape[1]\n",
    "output_size = 1\n",
    "batch_size = 50\n",
    "# placeholder\n",
    "x = tf.placeholder(tf.float32, [None, input_size], name='x')\n",
    "y = tf.placeholder(tf.float32, [None], name='y')\n",
    "\n",
    "# Variable\n",
    "W1 = tf.Variable(\n",
    "    tf.random_normal([input_size, input_size], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.zeros([input_size]), name='b1')\n",
    "h1 = tf.nn.relu(tf.add(tf.matmul(x, W1), b1))\n",
    "\n",
    "W2 = tf.Variable(\n",
    "    tf.random_normal([input_size, output_size], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.zeros([output_size]), name='b2')\n",
    "# ho = tf.add(tf.matmul(h1, W2), b2)\n",
    "\n",
    "prediction = tf.add(tf.matmul(h1, W2), b2)\n",
    "# cross_entropy = tf.reduce_mean(\n",
    "#     tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=ho))\n",
    "cross_entropy = tf.reduce_mean(tf.reduce_sum(tf.square(y-prediction), reduction_indices=[1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.003).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(y, prediction)\n",
    "acc_op = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T14:18:46.695109Z",
     "start_time": "2019-01-06T14:17:15.812856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 loss =  2795.695\n",
      "i: 10 loss =  2795.150\n",
      "[[0.1259771 ]\n",
      " [0.12607071]\n",
      " [0.12598923]\n",
      " ...\n",
      " [0.12646657]\n",
      " [0.12667699]\n",
      " [0.12640311]]\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    total_batch_len = int(len(df_x_train_all) / batch_size)\n",
    "    for i in range(20):\n",
    "        for j  in range(total_batch_len):\n",
    "#             batch_x = train_x_head[j*batch_size : (j+1)*batch_size]\n",
    "#             batch_y = df_y_train_all[j*batch_size : (j+1)*batch_size]\n",
    "#             _,loss = sess.run([optimizer,cross_entropy],feed_dict={x:batch_x,y:batch_y})\n",
    "            _,loss = sess.run([optimizer,cross_entropy],feed_dict={x:df_x_train_all,y:df_y_train_all})\n",
    "        if(i % 10 == 0):\n",
    "            print(\"i:\", i, \"loss = \", \"{:.3f}\".format(loss))\n",
    "    \n",
    "#     acc = sess.run(accuracy, feed_dict={x: np_x_test, y: np_y_test})\n",
    "#     print(acc)\n",
    "    pre = sess.run(prediction,feed_dict={x:df_x_train_all})\n",
    "    print(pre)\n",
    "    \n",
    "#     accuracy = sess.run(acc_op,feed_dict={x:np_x_test,y:np_y_test})\n",
    "#     print(\"Accuracy on validation set: %.9f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-06T13:43:47.150Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt('../data/zhengqi_sub.txt',pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T11:49:34.594885Z",
     "start_time": "2019-01-06T11:49:34.591749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T01:22:05.860334Z",
     "start_time": "2018-11-07T01:22:04.150776Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T01:22:07.005338Z",
     "start_time": "2018-11-07T01:22:05.863346Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_original = pd.DataFrame(pd.read_excel('personalroadriskassessv2test.xlsx'))\n",
    "\n",
    "df_test = df_test_original.drop(['SGFSSJ','WFSJ'],1)\n",
    "part_df_test = df_test[[\n",
    "    'ZJCX', 'LJJF', 'xb', 'jl',  'marrige', 'child', 'hnum',\n",
    "    'age', 'XZQH','SSRS','SWRS7','sghpzl' , 'SFSG'\n",
    "]]\n",
    "# 选择参数列\n",
    "X_select_elements = ['LJJF','ZJCX', 'age', 'xb', 'jl', 'child', 'marrige','XZQH','sghpzl','SSRS']\n",
    "# 测试数据\n",
    "test_X = np.array(part_df_test[X_select_elements])\n",
    "# 均值化\n",
    "minMax = MinMaxScaler()\n",
    "test_X = minMax.fit_transform(test_X)\n",
    "\n",
    "xs1 = test_X.shape[1]\n",
    "# ys1 = train_Y_oh.shape[1]\n",
    "ys1 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T01:22:07.226026Z",
     "start_time": "2018-11-07T01:22:07.007233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs1 10\n",
      "ys1 2\n"
     ]
    }
   ],
   "source": [
    "print('xs1',xs1)\n",
    "print('ys1',ys1)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape = [None,xs1],name = 'input')\n",
    "y = tf.placeholder(tf.float32,shape = [None,ys1],name = 'label')\n",
    "weights1 = tf.Variable(tf.random_normal([xs1,xs1]),name = 'weights1')\n",
    "bias1 = tf.Variable(tf.zeros([xs1]),name = 'bias1')\n",
    "a = tf.nn.relu(tf.matmul(x,weights1) + bias1)\n",
    "weights2 = tf.Variable(tf.random_normal([xs1,ys1]),name = 'weights2')\n",
    "bias2 = tf.Variable(tf.zeros([ys1]),name = 'bias2')\n",
    "z = tf.matmul(a,weights2) + bias2\n",
    "y_pred = tf.nn.softmax(z)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=z))\n",
    "# cost = tf.log(tf.clip_by_value(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=z)),1e-8,1.0))\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(y,1),tf.argmax(y_pred,1))\n",
    "acc_op = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "train_op = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "# loss = tf.log(tf.clip_by_value(y,1e-8,1.0))\n",
    "# loss = tf.log(tf.clip_by_value(tf.sigmoid(self.scores),1e-8,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T01:17:21.958340Z",
     "start_time": "2018-11-07T01:17:21.701245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt ./ckpt_dir/logistic.ckpt\n",
      "Restoring from checkpoint: ./ckpt_dir/logistic.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/logistic.ckpt\n",
      "Tensor(\"Softmax:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = './ckpt_dir'\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     ckpt = tf.train.latest_checkpoint(ckpt_dir)\n",
    "    print('ckpt',ckpt)\n",
    "    if ckpt:\n",
    "        print('Restoring from checkpoint: %s' % ckpt)\n",
    "#         saver.restore(sess, ckpt)\n",
    "        saver.restore(sess, ckpt_dir + '/logistic.ckpt')\n",
    "    \n",
    "#     评估模型  \n",
    "    print(y_pred)\n",
    "    possibility = sess.run(y_pred, feed_dict={x: test_X})\n",
    "    \n",
    "    possibility_array = np.array(possibility,dtype=float)\n",
    "    \n",
    "#     print('possibility',possibility)\n",
    "#     print('possibility.shape',possibility.shape)\n",
    "#     print('possibility.shape',type(possibility.shape))\n",
    "    \n",
    "    predictions = np.argmax(possibility, 1)\n",
    "    \n",
    "#     print('possibility[0]',possibility[:,0])\n",
    "#     print('possibility[0]',(possibility[:,0].shape))\n",
    "\n",
    "    #保存结果  \n",
    "    submission = pd.DataFrame({  \n",
    "        \"id\": df_test_original[\"id\"],  \n",
    "        \"SFSG\": predictions,\n",
    "        \"possibility_0\": possibility[:,0],\n",
    "        \"possibility_1\": possibility[:,1]\n",
    "    })  \n",
    "    submission.to_csv(\"SG-submission_re.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
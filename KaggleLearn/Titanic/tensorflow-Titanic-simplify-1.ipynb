{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 介绍 Introduction\n",
    "\n",
    "这个笔记是非常基础和简单的介绍融合模型的入门方式，特别是堆叠融合的变体。简而言之，堆叠用作第一级（基础），一些基本的机器学习模型（分类器）的预测，然后在第二级使用另一个模型来预测早期一级预测的输出。\n",
    "\n",
    "This notebook is a very basic and simple introductory primer to the method of ensembling models, in particular the variant of ensembling known as Stacking. In a nutshell stacking uses as a first-level (base), the predictions of a few basic machine learning models (classifiers) and then uses another model at the second-level to predict the output from the earlier first-level predictions.\n",
    "\n",
    "泰坦尼克号数据集是引入这一概念的主要方案，许多新手到Kaggle是从这里开始的。此外，即使堆叠技术已经为许多团队在Kaggle比赛获胜的方案，似乎在这个话题上缺少核心，所以我希望这款笔记本可以填补一些空白。\n",
    "\n",
    "The Titanic dataset is a prime candidate for introducing this concept as many newcomers to Kaggle start out here. Furthermore even though stacking has been responsible for many a team winning Kaggle competitions there seems to be a dearth of kernels on this topic so I hope this notebook can fill somewhat of that void.\n",
    "\n",
    "我自己也是Kaggle的新手，我设法学习的第一个合适的融合/堆叠脚本是由伟大的Faron在AllState Severity索赔比赛中写的。这笔记的教材大量借鉴了Faron的脚本，尽管我们是融合分类，他的是融合回归方案。但无论如何，请在这里查看他的脚本：\n",
    "\n",
    "I myself am quite a newcomer to the Kaggle scene as well and the first proper ensembling/stacking script that I managed to chance upon and study was one written in the AllState Severity Claims competition by the great Faron. The material in this notebook borrows heavily from Faron's script although ported to factor in ensembles of classifiers whilst his was ensembles of regressors. Anyway please check out his script here:\n",
    "\n",
    "[Stacking Starter](https://www.kaggle.com/mmueller/allstate-claims-severity/stacking-starter/run/390867) : by Faron\n",
    "\n",
    "现在在笔记本上我希望它能以一种直观和简洁的方式，做到公正并且传达出融合的概念。我的另一个独立的Kaggle脚本实现了完全相同的组合步骤（尽管有不同的参数），下面讨论的公共LB分数为0.808，这足以达到前9％，运行时间不到4分钟。 因此，我很确定有很多改进的空间，并添加到该脚本。 无论如何，请随时给我留下任何关于我如何改善的意见\n",
    "\n",
    "Now onto the notebook at hand and I hope that it manages to do justice and convey the concept of ensembling in an intuitive and concise manner. My other standalone Kaggle [script](https://www.kaggle.com/arthurtok/titanic/simple-stacking-with-xgboost-0-808) which implements exactly the same ensembling steps (albeit with different parameters) discussed below gives a Public LB score of 0.808 which is good enough to get to the top 9% and runs just under 4 minutes. Therefore I am pretty sure there is a lot of room to improve and add on to that script. Anyways please feel free to leave me any comments with regards to how I can improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:25.868816Z",
     "start_time": "2018-11-03T16:02:25.796904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征探索，工程和清洁 Feature Exploration, Engineering and Cleaning\n",
    "\n",
    "现在我们将进行常规的工作，就像大多数要点的结构一样，首先是探索手头的数据，找出可能的特征工程，以及对任何分类特征进行数字编码。\n",
    "\n",
    "Now we will proceed much like how most kernels in general are structured, and that is to first explore the data on hand, identify possible feature engineering opportunities as well as numerically encode any categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:27.323944Z",
     "start_time": "2018-11-03T16:02:27.299995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load in the train and test datasets\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "# Store our passenger ID for easy access\n",
    "PassengerId = test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:27.778132Z",
     "start_time": "2018-11-03T16:02:27.760790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "毫无疑问，我们的任务是以某种方式从分类变量中提取信息。\n",
    "\n",
    "Well it is no surprise that our task is to somehow extract the information out of the categorical variables\n",
    "\n",
    "**特征工程**\n",
    "\n",
    "**Feature Engineering**\n",
    "\n",
    "在这里，必须扩展到Sina的特征工程理念，这是非常全面和周全的笔记，所以请看看他的工作\n",
    "\n",
    "Here, credit must be extended to Sina's very comprehensive and well-thought out notebook for the feature engineering ideas so please check out his work\n",
    "\n",
    "[Titanic Best Working Classfier](https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier): by Sina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:31.223928Z",
     "start_time": "2018-11-03T16:02:30.576554Z"
    }
   },
   "outputs": [],
   "source": [
    "full_data = [train, test]\n",
    "\n",
    "# Some features of my own that I have added in\n",
    "# Gives the length of the name\n",
    "train['Name_length'] = train['Name'].apply(len)\n",
    "test['Name_length'] = test['Name'].apply(len)\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Feature engineering steps taken from Sina\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "# Create a New feature CategoricalAge\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:31.256418Z",
     "start_time": "2018-11-03T16:02:31.233552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>CategoricalFare</th>\n",
       "      <th>CategoricalAge</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>3</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name  Sex  Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1    1      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0    2      1      0   \n",
       "\n",
       "      Ticket  Fare Cabin  Embarked  Name_length  Has_Cabin  FamilySize  \\\n",
       "0  A/5 21171     0   NaN         0           23          0           2   \n",
       "1   PC 17599     3   C85         1           51          1           2   \n",
       "\n",
       "   IsAlone  CategoricalFare CategoricalAge  Title  \n",
       "0        0   (-0.001, 7.91]   (16.0, 32.0]      1  \n",
       "1        0  (31.0, 512.329]   (32.0, 48.0]      3  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:31.610408Z",
     "start_time": "2018-11-03T16:02:31.593545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name  Sex  Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    1    2      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)    0    2      1   \n",
       "\n",
       "   Parch  Ticket  Fare Cabin  Embarked  Name_length  Has_Cabin  FamilySize  \\\n",
       "0      0  330911     0   NaN         2           16          0           1   \n",
       "1      0  363272     0   NaN         0           32          0           2   \n",
       "\n",
       "   IsAlone  Title  \n",
       "0        1      1  \n",
       "1        0      3  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:32.307964Z",
     "start_time": "2018-11-03T16:02:32.300950Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 特征选择train[[\"Survived\"\n",
    "# # 准备训练和测试数据\n",
    "\n",
    "# print(train.shape)\n",
    "# y = train[\"Survived\"]\n",
    "# print(\"y.shape\",y.shape)\n",
    "\n",
    "# # print(train.shape)\n",
    "# tf_train = train.drop([\"Survived\"], axis = 1)\n",
    "# drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "# tf_train = tf_train.drop(drop_elements, axis = 1)\n",
    "# tf_train = tf_train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "# print(X_train.shape)\n",
    "# # X_train_ss_new = SelectKBest(f_classif, k=16).fit_transform(X_train, y)\n",
    "# # print(X_train_ss_new.shape)\n",
    "# X_train.head(2)\n",
    "\n",
    "# # X_train.to_csv('./out1.csv')\n",
    "\n",
    "\n",
    "# tf_train_new_pd = pd.DataFrame(tf_train_new)\n",
    "# tf_train_new_pd.to_csv('./out2.csv')\n",
    "\n",
    "# # 独热编码\n",
    "# y = (np.arange(2) == y[:,None]).astype(np.float32)\n",
    "# print(\"y.shape\",y.shape)\n",
    "# print(\"tf_train_new.shape\",tf_train_new.shape)\n",
    "# print(\"tf_labels.shape\",tf_labels.shape)\n",
    "# # 'Pclass','Sex','Parch','Fare','Embarked','Name_length','Has_Cabin','IsAlone','Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:32.862165Z",
     "start_time": "2018-11-03T16:02:32.859576Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(tf_labels.shape)\n",
    "# print(type(tf_labels))\n",
    "# tf_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:33.978978Z",
     "start_time": "2018-11-03T16:02:33.959435Z"
    }
   },
   "outputs": [],
   "source": [
    "# 特征选择\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "\n",
    "\n",
    "y = train[\"Survived\"]\n",
    "\n",
    "tf_train = train.drop([\"Survived\"], axis = 1)\n",
    "tf_train = tf_train.drop(drop_elements, axis = 1)\n",
    "tf_train = tf_train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "\n",
    "\n",
    "test  = test.drop(drop_elements, axis = 1)\n",
    "\n",
    "\n",
    "# from sklearn.feature_selection import SelectKBest,f_classif\n",
    "# tf_train_new = SelectKBest(f_classif, k=9).fit_transform(tf_train, y)\n",
    "# tf_test = test[['Pclass','Sex','Parch','Fare','Embarked','Name_length','Has_Cabin','IsAlone','Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:35.042520Z",
     "start_time": "2018-11-03T16:02:35.035075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape (891, 12)\n",
      "test.shape (418, 11)\n",
      "type(train) <class 'pandas.core.frame.DataFrame'>\n",
      "type(test) <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "train.head(3)\n",
    "\n",
    "print('train.shape',train.shape)\n",
    "print('test.shape',test.shape)\n",
    "print('type(train)',type(train))\n",
    "print('type(test)',type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:35.999490Z",
     "start_time": "2018-11-03T16:02:35.990954Z"
    }
   },
   "outputs": [],
   "source": [
    "# 用训练，测试，目标创建的Numpy数组提供给模型\n",
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "\n",
    "y_train = train['Survived'].ravel()\n",
    "train = train.drop(['Survived'], axis=1)\n",
    "x_train = train.values # Creates an array of the train data\n",
    "x_test = test.values # Creats an array of the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:37.452565Z",
     "start_time": "2018-11-03T16:02:37.442255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (891, 11)\n",
      "y_train.shape (891,)\n",
      "train.shape (891, 11)\n",
      "x_test.shape (418, 11)\n",
      "type(x_train) <class 'numpy.ndarray'>\n",
      "type(x_test) <class 'numpy.ndarray'>\n",
      "type(train) <class 'pandas.core.frame.DataFrame'>\n",
      "type(test) <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape\",x_train.shape)\n",
    "print(\"y_train.shape\",y_train.shape)\n",
    "print(\"train.shape\",train.shape)\n",
    "print(\"x_test.shape\",x_test.shape)\n",
    "print('type(x_train)',type(x_train))\n",
    "print('type(x_test)',type(x_test))\n",
    "print('type(train)',type(train))\n",
    "print('type(test)',type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T10:05:59.697675Z",
     "start_time": "2018-11-03T10:05:59.695032Z"
    }
   },
   "outputs": [],
   "source": [
    "# x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\n",
    "# x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在连接和加入第一级训练和测试预测集是x_train和x_test，我们现在能放入第二级训练模型\n",
    "\n",
    "Having now concatenated and joined both the first-level train and test predictions as x_train and x_test, we can now fit a second-level learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:51:17.913496Z",
     "start_time": "2018-11-03T15:51:17.901522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Parch  Fare  Embarked  Name_length  Has_Cabin  \\\n",
       "0       3    1    2      0     0         2           16          0   \n",
       "1       3    0    2      0     0         0           32          0   \n",
       "\n",
       "   FamilySize  IsAlone  Title  \n",
       "0           1        1      1  \n",
       "1           2        0      3  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T10:06:00.144244Z",
     "start_time": "2018-11-03T10:06:00.132975Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算精准度\n",
    "# def accuracy(predictions, labels):\n",
    "#   return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "#           / predictions.shape[0])\n",
    "# 保存结果\n",
    "# def savecsv(test_prediction_np, filename=\"submission_tf_titanic.csv\"):\n",
    "#     np.savetxt('submission_tf_titanic.csv', \n",
    "#            np.c_[range(1,len(x_test)+1),test_prediction_np], \n",
    "#            delimiter=',', \n",
    "#            header = 'PassengerId,Survived', \n",
    "#            comments = '', \n",
    "#            fmt='%d')\n",
    "#     StackingSubmission = pd.DataFrame({'PassengerId': PassengerId,'Survived': test_prediction_np })\n",
    "#     StackingSubmission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T10:06:00.294660Z",
     "start_time": "2018-11-03T10:06:00.278416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n",
      "(891,)\n",
      "(891, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Parch  Fare  Embarked  Name_length  Has_Cabin  \\\n",
       "0       3    1    1      0     0         0           23          0   \n",
       "1       1    0    2      0     3         1           51          1   \n",
       "\n",
       "   FamilySize  IsAlone  Title  \n",
       "0           2        0      1  \n",
       "1           2        0      3  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(train.shape)\n",
    "train.head(2)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:48.068756Z",
     "start_time": "2018-11-03T16:02:48.062548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2)\n"
     ]
    }
   ],
   "source": [
    "# 独热编码\n",
    "y_train = (np.arange(2) == y_train[:,None]).astype(np.float32)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:49.278987Z",
     "start_time": "2018-11-03T16:02:49.263744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 11)\n",
      "(268, 11)\n",
      "(623, 2)\n",
      "(268, 2)\n"
     ]
    }
   ],
   "source": [
    "#形成验证数据\n",
    "train_dataset, valid_dataset = model_selection.train_test_split(train, test_size=0.3, random_state=0)\n",
    "train_labels, valid_labels = model_selection.train_test_split(y_train, test_size=0.3, random_state=0)\n",
    "print(train_dataset.shape)\n",
    "print(valid_dataset.shape)\n",
    "print(train_labels.shape)\n",
    "print(valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:26:33.679932Z",
     "start_time": "2018-11-03T15:26:33.671732Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. 定义超参数和placeholder\n",
    "learning_rate = 0.5\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# placeholder\n",
    "# 原始数据的维度：9\n",
    "x = tf.placeholder(tf.float32, [None, 11])\n",
    "# 输出为0-1的one-hot编码\n",
    "y = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:26:33.868528Z",
     "start_time": "2018-11-03T15:26:33.830436Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. 定义参数w和b\n",
    "# hidden layer => w, b\n",
    "W1 = tf.Variable(tf.random_normal([11, 22], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([22]), name='b1')\n",
    "# output layer => w, b\n",
    "W2 = tf.Variable(tf.random_normal([22, 2], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([2]), name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:26:33.990183Z",
     "start_time": "2018-11-03T15:26:33.982019Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4. 构造隐层网络\n",
    "hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
    "hidden_out = tf.nn.relu(hidden_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:26:34.152708Z",
     "start_time": "2018-11-03T15:26:34.146327Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5. 构造输出（预测值）\n",
    "# 计算输出\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:26:34.297450Z",
     "start_time": "2018-11-03T15:26:34.279130Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6. BP部分—定义loss \n",
    "# 对n个标签计算交叉熵\n",
    "# 对m个样本取平均\n",
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped) + (1 - y) * tf.log(1 - y_clipped), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:26:34.599152Z",
     "start_time": "2018-11-03T15:26:34.445574Z"
    }
   },
   "outputs": [],
   "source": [
    "# 7. BP部分—定义优化算法\n",
    "# 创建优化器，确定优化目标\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:26:34.619856Z",
     "start_time": "2018-11-03T15:26:34.607743Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8. 定义初始化operation和准确率node\n",
    "# init operator\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# 创建准确率节点\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T15:26:35.436161Z",
     "start_time": "2018-11-03T15:26:34.754174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_train_new.shape (891, 9)\n",
      "y.shape (?, 2)\n",
      "8\n",
      "Epoch: 1 cost =  21.076\n",
      "Epoch: 2 cost =  23.831\n",
      "Epoch: 3 cost =  23.831\n",
      "Epoch: 4 cost =  23.831\n",
      "Epoch: 5 cost =  23.831\n",
      "Epoch: 6 cost =  23.831\n",
      "Epoch: 7 cost =  23.831\n",
      "Epoch: 8 cost =  23.831\n",
      "Epoch: 9 cost =  23.831\n",
      "Epoch: 10 cost =  23.831\n",
      "accuracy 0.37313432\n"
     ]
    }
   ],
   "source": [
    "# 9 开始训练\n",
    "# 创建session\n",
    "print(\"tf_train_new.shape\",tf_train_new.shape)\n",
    "print(\"y.shape\",y.shape)\n",
    "with tf.Session() as sess:\n",
    "    # 变量初始化\n",
    "    sess.run(init_op)\n",
    "    total_batch = int(len(x_train) / batch_size)\n",
    "    print(total_batch)\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "#             batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)\n",
    "            _, c = sess.run([optimizer, cross_entropy], feed_dict={x: train_dataset, y: train_labels})\n",
    "#     sess.run(train_step, feed_dict={xs: tf_train_new, ys: y, keep_prob: 0.7})\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost = \", \"{:.3f}\".format(avg_cost))\n",
    "    print(\"accuracy\",sess.run(accuracy, feed_dict={x: valid_dataset, y: valid_labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:02:55.387161Z",
     "start_time": "2018-11-03T16:02:55.123061Z"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape = [None,11],name = 'input')\n",
    "y = tf.placeholder(tf.float32,shape = [None,2],name = 'label')\n",
    "weights1 = tf.Variable(tf.random_normal([11,11]),name = 'weights1')\n",
    "bias1 = tf.Variable(tf.zeros([11]),name = 'bias1')\n",
    "a = tf.nn.relu(tf.matmul(x,weights1) + bias1)\n",
    "weights2 = tf.Variable(tf.random_normal([11,2]),name = 'weights2')\n",
    "bias2 = tf.Variable(tf.zeros([2]),name = 'bias2')\n",
    "z = tf.matmul(a,weights2) + bias2\n",
    "y_pred = tf.nn.softmax(z)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=z))\n",
    "correct_pred = tf.equal(tf.argmax(y,1),tf.argmax(y_pred,1))\n",
    "acc_op = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "train_op = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-03T16:04:01.473950Z",
     "start_time": "2018-11-03T16:03:36.109420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from checkpoint: ./ckpt_dir/logistic.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/logistic.ckpt\n",
      "Epoch:    0, total loss = 443.474575500899\n",
      "Accuracy on validation set: 0.794776142\n",
      "Epoch:    1, total loss = 442.164824451611\n",
      "Epoch:    2, total loss = 440.860925284144\n",
      "Epoch:    3, total loss = 439.851188335454\n",
      "Epoch:    4, total loss = 439.304571123397\n",
      "Epoch:    5, total loss = 438.516713683077\n",
      "Epoch:    6, total loss = 437.851598415404\n",
      "Epoch:    7, total loss = 437.402197927748\n",
      "Epoch:    8, total loss = 436.649372247949\n",
      "Epoch:    9, total loss = 436.313598281255\n",
      "Epoch:   10, total loss = 436.223107103812\n",
      "Accuracy on validation set: 0.802238822\n",
      "Epoch:   11, total loss = 436.664002979633\n",
      "Epoch:   12, total loss = 436.219860768551\n",
      "Epoch:   13, total loss = 436.032932988287\n",
      "Epoch:   14, total loss = 435.878378415659\n",
      "Epoch:   15, total loss = 434.239313399410\n",
      "Epoch:   16, total loss = 434.418905993610\n",
      "Epoch:   17, total loss = 432.998642806640\n",
      "Epoch:   18, total loss = 432.850291590216\n",
      "Epoch:   19, total loss = 431.851761704714\n",
      "Epoch:   20, total loss = 431.204731913136\n",
      "Accuracy on validation set: 0.817164183\n",
      "Epoch:   21, total loss = 430.157922679386\n",
      "Epoch:   22, total loss = 430.216549592220\n",
      "Epoch:   23, total loss = 429.611072522015\n",
      "Epoch:   24, total loss = 430.131135105614\n",
      "Epoch:   25, total loss = 429.196562424295\n",
      "Epoch:   26, total loss = 428.467172952081\n",
      "Epoch:   27, total loss = 428.578514868277\n",
      "Epoch:   28, total loss = 427.962155731613\n",
      "Epoch:   29, total loss = 427.365736048567\n",
      "training complete!\n",
      "Accuracy on validation set: 0.809701502\n",
      "Accuracy on validation set (numpy): 0.809701502\n",
      "x_test.shape (418, 11)\n",
      "X_test.shape (418, 6)\n",
      "test.shape (418, 11)\n",
      "type(x_test) <class 'numpy.ndarray'>\n",
      "type(X_test) <class 'pandas.core.frame.DataFrame'>\n",
      "type(test) <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 存档入口\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# 在Saver声明之后定义的变量将不会被存储\n",
    "# non_storable_variable = tf.Variable(777)\n",
    "\n",
    "ckpt_dir = './ckpt_dir'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    ckpt = tf.train.latest_checkpoint(ckpt_dir)\n",
    "    if ckpt:\n",
    "        print('Restoring from checkpoint: %s' % ckpt)\n",
    "        saver.restore(sess, ckpt)\n",
    "\n",
    "    for epoch in range(30):\n",
    "        total_loss = 0.\n",
    "        for i in range(len(x_train)):\n",
    "            feed_dict = {x: [x_train[i]],y:[y_train[i]]}\n",
    "            _,loss = sess.run([train_op,cost],feed_dict=feed_dict)\n",
    "            total_loss +=loss\n",
    "        print('Epoch: %4d, total loss = %.12f' % (epoch,total_loss))\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy = sess.run(acc_op,feed_dict={x:valid_dataset,y:valid_labels})\n",
    "            print(\"Accuracy on validation set: %.9f\" % accuracy)\n",
    "            saver.save(sess, ckpt_dir + '/logistic.ckpt')\n",
    "    print('training complete!')\n",
    "\n",
    "    accuracy = sess.run(acc_op,feed_dict={x:valid_dataset,y:valid_labels})\n",
    "    print(\"Accuracy on validation set: %.9f\" % accuracy)\n",
    "    pred = sess.run(y_pred,feed_dict={x:valid_dataset})\n",
    "    correct = np.equal(np.argmax(pred,1),np.argmax(valid_labels,1))\n",
    "    numpy_accuracy = np.mean(correct.astype(np.float32))\n",
    "    print(\"Accuracy on validation set (numpy): %.9f\" % numpy_accuracy)\n",
    "\n",
    "    saver.save(sess, ckpt_dir + '/logistic.ckpt')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    测试数据的清洗和训练数据一样，两者可以共同完成\n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "    # 读测试数据  \n",
    "    test_data = pd.read_csv('./input/test.csv')  \n",
    "\n",
    "    #数据清洗, 数据预处理  \n",
    "    test_data.loc[test_data['Sex']=='male','Sex'] = 0\n",
    "    test_data.loc[test_data['Sex']=='female','Sex'] = 1 \n",
    "\n",
    "    age = test_data[['Age','Sex','Parch','SibSp','Pclass']]\n",
    "    age_notnull = age.loc[(test_data.Age.notnull())]\n",
    "    age_isnull = age.loc[(test_data.Age.isnull())]\n",
    "    X = age_notnull.values[:,1:]\n",
    "    Y = age_notnull.values[:,0]\n",
    "    rfr = RandomForestRegressor(n_estimators=1000,n_jobs=-1)\n",
    "    rfr.fit(X,Y)\n",
    "    predictAges = rfr.predict(age_isnull.values[:,1:])\n",
    "    test_data.loc[(test_data.Age.isnull()),'Age'] = predictAges\n",
    "\n",
    "    test_data['Embarked'] = test_data['Embarked'].fillna('S')\n",
    "    test_data.loc[test_data['Embarked'] == 'S','Embarked'] = 0\n",
    "    test_data.loc[test_data['Embarked'] == 'C','Embarked'] = 1\n",
    "    test_data.loc[test_data['Embarked'] == 'Q','Embarked'] = 2\n",
    "\n",
    "    test_data.drop(['Cabin'],axis=1,inplace=True)\n",
    "\n",
    "    #特征选择  \n",
    "    X_test = test_data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare']]  \n",
    "    print('x_test.shape',x_test.shape)\n",
    "    print('X_test.shape',X_test.shape)\n",
    "    print('test.shape',test.shape)\n",
    "    \n",
    "    print('type(x_test)',type(x_test))\n",
    "    print('type(X_test)',type(X_test))\n",
    "    print('type(test)',type(test))\n",
    "#     print(x_test)\n",
    "#     print(X_test)\n",
    "    \n",
    "#     评估模型  \n",
    "    predictions = np.argmax(sess.run(y_pred, feed_dict={x: test}), 1)  \n",
    "\n",
    "    #保存结果  \n",
    "    submission = pd.DataFrame({  \n",
    "        \"PassengerId\": test_data[\"PassengerId\"],  \n",
    "        \"Survived\": predictions  \n",
    "    })  \n",
    "    submission.to_csv(\"titanic-submission.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow deep NN\n",
    "#### 用MNIST数据和TensorFlow包来深度学习的高级教程 \n",
    "#### A high-level tutorial into Deep Learning using MNIST data and TensorFlow library.\n",
    "by [@kakauandme](https://twitter.com/KaKaUandME) and [@thekoshkina](https://twitter.com/thekoshkina)\n",
    "\n",
    "Accuracy: 0.99\n",
    "\n",
    "**必备知识** 基础编码技巧，一点线性代数，特别是矩阵操作，可能也要明白如何图片是如何存储到计算机内存。和开始机器学习一样，我们建议学习吴恩达的课程\n",
    "\n",
    "**Prerequisites:** fundamental coding skills, a bit of linear algebra, especially matrix operations and perhaps understanding how images are stored in computer memory. To start with machine learning, we suggest [coursera course](https://www.coursera.org/learn/machine-learning) by Andrew Ng.\n",
    "\n",
    "笔记:\n",
    "Note: \n",
    "通过随意分叉和调整常量，来调整网络行为和探索如何去改变算法表现和精准度。此外用TensorFlow 图部分也能调整学习目标\n",
    "\n",
    "*Feel free to fork and adjust* CONSTANTS *to tweak network behaviour and explore how it changes algorithm performance and accuracy. Besides **TensorFlow graph** section can also be modified for learning purposes.*\n",
    "\n",
    "非常推荐输出每个你不是100%了解的变量。也能使用你的本地环境让她可视化和调试\n",
    "\n",
    "*It is highly recommended printing every variable that isn’t 100% clear for you. Also, [tensorboard](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html) can be used on a local environment for visualisation and debugging.*\n",
    "\n",
    "## 包和设置 Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection\n",
    "# settings\n",
    "LEARNING_RATE = 1e-4\n",
    "# set to 20000 on local environment to get 0.99 accuracy\n",
    "TRAINING_ITERATIONS = 25       \n",
    "    \n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# set to 0 to train on all available data\n",
    "VALIDATION_SIZE = 2000\n",
    "\n",
    "# image number to output\n",
    "IMAGE_TO_DISPLAY = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理 Data preparation\n",
    "开始，我们读取数据train.csv有42000行和785列。每一行代表一个手写的数字图片和一个标签用于表示这个图片是几的数字\n",
    "\n",
    "To start, we read provided data. The *train.csv* file contains 42000 rows and 785 columns. Each row represents an image of a handwritten digit and a label with the value of this digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data(42000,785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "# read training data from CSV file \n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "print('data({0[0]},{0[1]})'.format(data.shape))\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个图片是一个拉伸的数组的像素值\n",
    "\n",
    "Every image is a \"stretched\" array of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images(42000,784)\n"
     ]
    }
   ],
   "source": [
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "# 数据乘以1/255，0-255->0-1\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "print('images({0[0]},{0[1]})'.format(images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "吧784像素值转求出28*28像素\n",
    "\n",
    "In this case it's 784 pixels => 28 * 28px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size => 784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    }
   ],
   "source": [
    "image_size = images.shape[1]\n",
    "print ('image_size => {0}'.format(image_size))\n",
    "\n",
    "# in this case all images are square\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出一个图片，我们改造像素值向量变成二维数组，这基本是一个灰度图像\n",
    "\n",
    "To output one of the images, we reshape this long string of pixels into a 2-dimensional array, which is basically a grayscale image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相应的标签是0-9，描述每个图像是哪个数字\n",
    "\n",
    "The corresponding labels are numbers between 0 and 9, describing which digit a given image is of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_flat(42000)\n",
      "labels_flat[10] => 8\n"
     ]
    }
   ],
   "source": [
    "# print(data)\n",
    "\n",
    "# labels_flat = data[[0]].values.ravel()\n",
    "# iiitttttrr\n",
    "labels_flat = data.iloc[:,0].values\n",
    "# 打印标签列长度\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "# 打印第X行的图片对应的标签\n",
    "print ('labels_flat[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels_flat[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个案例里，有10个不同的数字，标签，分类\n",
    "\n",
    "In this case, there are ten different digits/labels/classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_count = 10\n"
     ]
    }
   ],
   "source": [
    "# unique是返回数组的唯一元素，然后获取形状位置0\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "# 打印总数\n",
    "print('labels_count = {0}'.format(labels_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大多数分类程序使用独热向量（独热编码）。独热向量是一个包含1个1和剩余都是0的向量.在这个案例，数字几就是第几个是1的独热向量。\n",
    "\n",
    "For most classification problems \"one-hot vectors\" are used. A one-hot vector is a vector that contains a single element equal to 1 and the rest of the elements equal to 0. In this case, the *nth* digit is represented as a zero vector with 1 in the *nth* position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels(42000,10)\n",
      "labels[10] => [0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 转换类标签标量到独热编码\n",
    "# convert class labels from scalars to one-hot vectors\n",
    "# 0 => [1 0 0 0 0 0 0 0 0 0]\n",
    "# 1 => [0 1 0 0 0 0 0 0 0 0]\n",
    "# ...\n",
    "# 9 => [0 0 0 0 0 0 0 0 0 1]\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "#    labels_dense = [1 0 1 ..., 7 6 9]\n",
    "#    num_classes = 10\n",
    "    num_labels = labels_dense.shape[0]\n",
    "#    num_labels = 42000\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "#    index_offset = [     0     10     20 ..., 419970 419980 419990]\n",
    "#    index_offset.shape = (42000,)\n",
    "#    创建一个全0数组\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "#     print(labels_one_hot)\n",
    "#    labels_one_hot.shape = (42000,10)\n",
    "#    flat是一个循环迭代器,通过乘以10，来给每一行的数字打上one hot的1\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "#     print(labels_one_hot.flat[22])\n",
    "    return labels_one_hot\n",
    "# print(labels_one_hot.flat[21])\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "print('labels({0[0]},{0[1]})'.format(labels.shape))\n",
    "print ('labels[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后我们留出部分数据作为验证.在机器学习中，必须有一个独立的数据集，它不参与训练，用来确保我们训练的数据可以验证。\n",
    "\n",
    "Lastly we set aside data for validation. It's essential in machine learning to have a separate dataset which doesn't take part in the training and is used to make sure that what we've learned can actually be generalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels.shape (40000, 10)\n",
      "train_images(40000,784)\n",
      "validation_images(2000,784)\n",
      "validation_labels(2000,784)\n",
      "train_labels.shape (29400, 10)\n",
      "train_images(29400,784)\n",
      "validation_images(12600,784)\n",
      "validation_labels(12600,784)\n"
     ]
    }
   ],
   "source": [
    "# 分割数据，分成验证集和训练集\n",
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]\n",
    "print(\"train_labels.shape\",train_labels.shape)\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))\n",
    "print('validation_labels({0[0]},{0[1]})'.format(validation_images.shape))\n",
    "\n",
    "train_images, validation_images = model_selection.train_test_split(images, test_size=0.3, random_state=0)\n",
    "train_labels, validation_labels = model_selection.train_test_split(labels, test_size=0.3, random_state=0)\n",
    "print(\"train_labels.shape\",train_labels.shape)\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))\n",
    "print('validation_labels({0[0]},{0[1]})'.format(validation_images.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images(28000,784)\n"
     ]
    }
   ],
   "source": [
    "# read test data from CSV file \n",
    "test_images = pd.read_csv('test.csv').values\n",
    "test_images = test_images.astype(np.float)\n",
    "\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "print('test_images({0[0]},{0[1]})'.format(test_images.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算精准度\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 保存结果\n",
    "def savecsv(test_prediction_np,savename = 'submission_uda_dr.csv'):\n",
    "    np.savetxt(savename, \n",
    "           np.c_[range(1,len(test_images)+1),test_prediction_np], \n",
    "           delimiter=',', \n",
    "           header = 'ImageId,Label', \n",
    "           comments = '', \n",
    "           fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size=784\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 0.90029\n",
    "batch_size = 128  \n",
    "regularation_param = 0.0001  \n",
    "  \n",
    "graph = tf.Graph()  \n",
    "with graph.as_default():\n",
    "    # -----------------------------------------1\n",
    "    # 输入 \n",
    "    # placeholder 插入一个待初始化的张量占位符\n",
    "    # 重要事项：这个张量被求值时会产生错误。 \n",
    "    # 它的值必须在Session.run(), Tensor.eval() 或 Operation.run() 中使用feed_dict的这个可选参数来填充。\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, labels_count))\n",
    "    # 创建一个常量张量\n",
    "    # tf_valid_dataset = Tensor(\"Const:0\", shape=(10000, 784), dtype=float32)\n",
    "\n",
    "    \n",
    "    tf_valid_dataset = tf.constant(validation_images)\n",
    "    tf_test_dataset = tf.constant(test_images)\n",
    "    # ------------------------------------------2\n",
    "    # 变量\n",
    "    # 当你训练一个模型的时候，你使用变量去保存和更新参数。\n",
    "    # 在Tensorflow中变量是内存缓冲区中保存的张量（tensor）。\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size, labels_count]))\n",
    "    biases = tf.Variable(tf.zeros([labels_count]))\n",
    "    print(\"image_size=%d\" % image_size)\n",
    "    # -------------------------------------------3\n",
    "    # 训练计算.\n",
    "\n",
    "    \n",
    "    # 转换数据类型\n",
    "    tf_valid_dataset = tf.to_float(tf_valid_dataset)\n",
    "    tf_test_dataset = tf.to_float(tf_test_dataset)\n",
    "    \n",
    "    train_logits = tf.matmul(tf_train_dataset, weights) +  biases\n",
    "    \n",
    "#     print(type(tf_train_dataset))\n",
    "#     print(type(tf_valid_dataset))\n",
    "#     print(type(tf_test_dataset))\n",
    "#     print(tf_train_dataset.dtype)\n",
    "#     print(tf_valid_dataset.dtype)\n",
    "#     print(tf_test_dataset.dtype)\n",
    "    \n",
    "#     print(tf_valid_dataset.shape)\n",
    "#     print(weights.shape)\n",
    "    \n",
    "    \n",
    "    valid_logits = tf.matmul(tf_valid_dataset, weights) + biases\n",
    "    test_logits = tf.matmul(tf_test_dataset, weights) +  biases\n",
    "    # reduce_mean可跨越维度的计算张量各元素的平均值\n",
    "    # 计算loss是代价值，也就是我们要最小化的值\n",
    "    # 第一个参数logits：就是神经网络最后一层的输出，\n",
    "    # 如果有batch的话，它的大小就是[batchsize，num_classes]，单样本的话，大小就是num_classes\n",
    "    # 第二个参数labels：实际的标签，大小同上\n",
    "    # 第一步是先对网络最后一层的输出做一个softmax，这一步通常是求取输出属于某一类的概率\n",
    "    # 第二步是softmax的输出向量[Y1，Y2,Y3...]和样本的实际标签做一个交叉熵\n",
    "    # 注意！！！这个函数的返回值并不是一个数，而是一个向量.\n",
    "    # 如果要求交叉熵，我们要再做一步tf.reduce_sum操作,就是对向量里面所有元素求和，最后才得到. \n",
    "    # 如果求loss，则要做一步tf.reduce_mean操作，对向量求均值！\n",
    "    \n",
    "    # 如果直接将l2_loss加到train_loss上，每次的train_loss都特别大，几乎只取决于l2_loss\n",
    "    # 为了让原本的train_loss与l2_loss都能较好地对参数调整方向起作用，它们应当至少在同一个量级\n",
    "    # 这里还有一个重要的点，Hyper Parameter: β\n",
    "    # 我觉得这是一个拍脑袋参数，取什么值都行，但效果会不同，我这里解释一下我取β=0.001的理由\n",
    "    # 为了让原本的train_loss与l2_loss都能较好地对参数调整方向起作用，它们应当至少在同一个量级\n",
    "    # 观察不加l2_loss，step 0 时，train_loss在300左右\n",
    "    # 加l2_loss后， step 0 时，train_loss在300000左右\n",
    "    # 因此给l2_loss乘0.0001使之降到同一个量级\n",
    "    # 原始 loss=18\n",
    "    # loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=train_logits, labels=tf_train_labels))\n",
    "    # 原始L2后loss=58000\n",
    "    #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=train_logits)) * tf.nn.l2_loss(weights)  \n",
    "    # 使用Hyper Parameter 0.0001 相乘来降低L2的影响，使用后loss=16\n",
    "    hpl2 = regularation_param * tf.nn.l2_loss(weights)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=train_logits))\n",
    "    print(loss)\n",
    "    loss = tf.add(loss, hpl2)\n",
    "\n",
    "    \n",
    "    #loss = tf.add(loss,\n",
    "    # -------------------------------------------4\n",
    "    # 最优化.因为深度学习常见的是对于梯度的优化，也就是说，优化器最后其实就是各种对于梯度下降算法的优化。 \n",
    "    # 函数training()通过梯度下降法为最小化损失函数增加了相关的优化操作，在训练过程中，\n",
    "    # 先实例化一个优化函数，比如 tf.train.GradientDescentOptimizer，并基于一定的学习率进行梯度优化训练：\n",
    "    # learning_rate参数：要使用的学习率 \n",
    "    # minimize：非常常用的一个函数 通过更新var_list来减小loss，这个函数就是前面compute_gradients() 和apply_gradients().的结合\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    \n",
    "    #--------------------------------------------5\n",
    "    # 预测训练, 验证,和测试数据.\n",
    "    # tf.nn.softmax仅产生将softmax function应用于输入张量的结果。 \n",
    "    # softmax 压扁输入，使sum(输入)= 1;这是一种正常化的方式。 \n",
    "    # softmax的输出形状与输入相同 – 它只是对值进行归一化。 \n",
    "    # softmax的输出可以解释为概率。\n",
    "    # a = tf.constant(np.array([[.1, .3, .5, .9]]))\n",
    "    # print s.run(tf.nn.softmax(a))\n",
    "    # [[ 0.16838508  0.205666    0.25120102  0.37474789]]\n",
    "    train_prediction = tf.nn.softmax(train_logits)\n",
    "    valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    test_prediction = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.94586\n",
    "batch_size = 128  \n",
    "hidden_nodes = 1024\n",
    "regularation_param = 0.0001  \n",
    "keep_prob = 0.8\n",
    "  \n",
    "graph = tf.Graph()  \n",
    "with graph.as_default():\n",
    "    # -----------------------------------------1\n",
    "    # 输入 \n",
    "    # placeholder 插入一个待初始化的张量占位符\n",
    "    # 重要事项：这个张量被求值时会产生错误。 \n",
    "    # 它的值必须在Session.run(), Tensor.eval() 或 Operation.run() 中使用feed_dict的这个可选参数来填充。\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, labels_count))\n",
    "    # 创建一个常量张量\n",
    "    # tf_valid_dataset = Tensor(\"Const:0\", shape=(10000, 784), dtype=float32)\n",
    "\n",
    "    \n",
    "    tf_valid_dataset = tf.constant(validation_images)\n",
    "    tf_test_dataset = tf.constant(test_images)\n",
    "    # ------------------------------------------2\n",
    "    # 变量\n",
    "    # 当你训练一个模型的时候，你使用变量去保存和更新参数。\n",
    "    # 在Tensorflow中变量是内存缓冲区中保存的张量（tensor）。\n",
    "    #weights = tf.Variable(tf.truncated_normal([image_size, labels_count]))\n",
    "    #biases = tf.Variable(tf.zeros([labels_count]))\n",
    "    \n",
    "    \n",
    "    # 第一层\n",
    "    # truncated_normal 从一个正态分布片段中输出随机数值,\n",
    "    # 生成的值会遵循一个指定了平均值和标准差的正态分布，只保留两个标准差以内的值，超出的值会被弃掉重新生成。\n",
    "    # 返回 一个指定形状并用正态分布片段的随机值填充的张量\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size, hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    \n",
    "    # 第二层\n",
    "    weights2 = tf.Variable(tf.truncated_normal([hidden_nodes, labels_count]))\n",
    "    biases2 = tf.Variable(tf.zeros([labels_count]))\n",
    "    \n",
    "    \n",
    "    #print(\"image_size=%d\" % image_size)\n",
    "    # -------------------------------------------3\n",
    "    # 训练计算.\n",
    "\n",
    "    \n",
    "    # 转换数据类型\n",
    "    tf_valid_dataset = tf.to_float(tf_valid_dataset)\n",
    "    tf_test_dataset = tf.to_float(tf_test_dataset)\n",
    "    \n",
    "    #使用dropout\n",
    "    drop = tf.nn.dropout(tf_train_dataset, keep_prob=keep_prob)\n",
    "    \n",
    "    # train_logits = tf.matmul(tf_train_dataset, weights) +  biases\n",
    "    # valid_logits = tf.matmul(tf_valid_dataset, weights) + biases\n",
    "    # test_logits = tf.matmul(tf_test_dataset, weights) +  biases\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_logits = tf.add(tf.matmul(drop, weights1), biases1)\n",
    "    train_logits = tf.nn.relu(train_logits)\n",
    "    train_logits = tf.add(tf.matmul(train_logits,weights2),biases2)\n",
    "\n",
    "    valid_logits = tf.add(tf.matmul(tf_valid_dataset, weights1),biases1)\n",
    "    valid_logits = tf.nn.relu(valid_logits)\n",
    "    valid_logits = tf.add(tf.matmul(valid_logits,weights2),biases2)\n",
    "\n",
    "    test_logits = tf.add(tf.matmul(tf_test_dataset, weights1),biases1)\n",
    "    test_logits = tf.nn.relu(test_logits)\n",
    "    test_logits = tf.add(tf.matmul(test_logits,weights2),biases2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # reduce_mean可跨越维度的计算张量各元素的平均值\n",
    "    # 计算loss是代价值，也就是我们要最小化的值\n",
    "    # 第一个参数logits：就是神经网络最后一层的输出，\n",
    "    # 如果有batch的话，它的大小就是[batchsize，num_classes]，单样本的话，大小就是num_classes\n",
    "    # 第二个参数labels：实际的标签，大小同上\n",
    "    # 第一步是先对网络最后一层的输出做一个softmax，这一步通常是求取输出属于某一类的概率\n",
    "    # 第二步是softmax的输出向量[Y1，Y2,Y3...]和样本的实际标签做一个交叉熵\n",
    "    # 注意！！！这个函数的返回值并不是一个数，而是一个向量.\n",
    "    # 如果要求交叉熵，我们要再做一步tf.reduce_sum操作,就是对向量里面所有元素求和，最后才得到. \n",
    "    # 如果求loss，则要做一步tf.reduce_mean操作，对向量求均值！\n",
    "    \n",
    "    # 如果直接将l2_loss加到train_loss上，每次的train_loss都特别大，几乎只取决于l2_loss\n",
    "    # 为了让原本的train_loss与l2_loss都能较好地对参数调整方向起作用，它们应当至少在同一个量级\n",
    "    # 这里还有一个重要的点，Hyper Parameter: β\n",
    "    # 我觉得这是一个拍脑袋参数，取什么值都行，但效果会不同，我这里解释一下我取β=0.001的理由\n",
    "    # 为了让原本的train_loss与l2_loss都能较好地对参数调整方向起作用，它们应当至少在同一个量级\n",
    "    # 观察不加l2_loss，step 0 时，train_loss在300左右\n",
    "    # 加l2_loss后， step 0 时，train_loss在300000左右\n",
    "    # 因此给l2_loss乘0.0001使之降到同一个量级\n",
    "    # 原始 loss=18\n",
    "    # loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=train_logits, labels=tf_train_labels))\n",
    "    # 原始L2后loss=58000\n",
    "    #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=train_logits)) * tf.nn.l2_loss(weights)  \n",
    "    # 使用Hyper Parameter 0.0001 相乘来降低L2的影响，使用后loss=16\n",
    "    hpl2 = regularation_param * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=train_logits))\n",
    "    loss = tf.add(loss , hpl2)\n",
    "    \n",
    "\n",
    "    \n",
    "    #loss = tf.add(loss,\n",
    "    # -------------------------------------------4\n",
    "    # 最优化.因为深度学习常见的是对于梯度的优化，也就是说，优化器最后其实就是各种对于梯度下降算法的优化。 \n",
    "    # 函数training()通过梯度下降法为最小化损失函数增加了相关的优化操作，在训练过程中，\n",
    "    # 先实例化一个优化函数，比如 tf.train.GradientDescentOptimizer，并基于一定的学习率进行梯度优化训练：\n",
    "    # learning_rate参数：要使用的学习率 \n",
    "    # minimize：非常常用的一个函数 通过更新var_list来减小loss，这个函数就是前面compute_gradients() 和apply_gradients().的结合\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    \n",
    "    #--------------------------------------------5\n",
    "    # 预测训练, 验证,和测试数据.\n",
    "    # tf.nn.softmax仅产生将softmax function应用于输入张量的结果。 \n",
    "    # softmax 压扁输入，使sum(输入)= 1;这是一种正常化的方式。 \n",
    "    # softmax的输出形状与输入相同 – 它只是对值进行归一化。 \n",
    "    # softmax的输出可以解释为概率。\n",
    "    # a = tf.constant(np.array([[.1, .3, .5, .9]]))\n",
    "    # print s.run(tf.nn.softmax(a))\n",
    "    # [[ 0.16838508  0.205666    0.25120102  0.37474789]]\n",
    "    train_prediction = tf.nn.softmax(train_logits)\n",
    "    valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    test_prediction = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 259.307404\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 26.1%\n",
      "Minibatch loss at step 500: 31.825253\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 1000: 28.782307\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 1500: 27.505709\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 2000: 26.266083\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 2500: 24.772188\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 93.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001  \n",
    "print (test_images.shape[0]//batch_size)\n",
    "with tf.Session(graph=graph) as session:  \n",
    "    tf.initialize_all_variables().run()  \n",
    "    print(\"Initialized\")  \n",
    "    for step in range(num_steps):  \n",
    "        # 在训练数据中选择一个已被随机化的偏移量.\n",
    "        # 提醒: 我们能使用更好的随机化穿过所有数据.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)  \n",
    "        # 生成一个小批量数据\n",
    "        batch_data = train_images[offset:(offset + batch_size), :]  \n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]  \n",
    "        # feed_dict的作用是给使用placeholder创建出来的tensor赋值。\n",
    "        # 其实，他的作用更加广泛：feed 使用一个 值临时替换一个 op 的输出结果. \n",
    "        # 你可以提供 feed 数据作为 run() 调用的参数. feed 只在调用它的方法内有效, 方法结束, feed 就会消失.\n",
    "        #  传递值到tf的命名空间  \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}  \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)  \n",
    "        if (step % 500 == 0):  \n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))  \n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))  \n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), validation_labels))  \n",
    "    # 获取结果，用于保存\n",
    "    test_prediction_np = test_prediction.eval()\n",
    "    test_prediction_np = np.argmax(test_prediction_np, 1)\n",
    "    savecsv(test_prediction_np)\n",
    "    #predicted_lables = np.zeros(test_images.shape[0])\n",
    "    #for i in range(0,test_images.shape[0]//BATCH_SIZE):\n",
    "    #    predicted_lables[i*BATCH_SIZE : (i+1)*BATCH_SIZE] = test_prediction.eval(feed_dict={x: test_images[i*BATCH_SIZE : (i+1)*BATCH_SIZE], keep_prob: 1.0})\n",
    "\n",
    "    #print(test_prediction.eval().shape)\n",
    "\n",
    "\n",
    "#     predictions = np.argmax(sess.run(y_pred, feed_dict={X: X_test}), 1)  \n",
    "    # print(\"Test accuracy: %.1f%% with regularation_param = %f \" %( accuracy(test_prediction.eval(), test_labels), regularation_param)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10)\n"
     ]
    }
   ],
   "source": [
    "# 0.98000\n",
    "batch_size = 128\n",
    "# 隐藏节点\n",
    "hidden_nodes = 2048\n",
    "# L2缩放率\n",
    "regularation_param = 0.0001  \n",
    "\n",
    "graph = tf.Graph()  \n",
    "def compute_logits(data, weightss, biasess, dropout_vals=None):  \n",
    "    temp = data  \n",
    "    if dropout_vals:  \n",
    "        for w,b,d in zip(weightss[:-1], biasess[:-1], dropout_vals[:-1]):  \n",
    "            temp = tf.nn.relu_layer(tf.nn.dropout(temp, d), w, b)  \n",
    "        temp = tf.matmul(temp, weightss[-1]) + biasess[-1]  \n",
    "    else:  \n",
    "        for w,b in zip(weightss[:-1], biasess[:-1]):\n",
    "            temp = tf.nn.relu_layer(temp, w, b)  \n",
    "        temp = tf.matmul(temp, weightss[-1]) + biasess[-1]  \n",
    "    return temp  \n",
    "with graph.as_default():\n",
    "    # -----------------------------------------1\n",
    "    # 输入 \n",
    "    # placeholder 插入一个待初始化的张量占位符\n",
    "    # 重要事项：这个张量被求值时会产生错误。 \n",
    "    # 它的值必须在Session.run(), Tensor.eval() 或 Operation.run() 中使用feed_dict的这个可选参数来填充。\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, labels_count))\n",
    "    \n",
    "\n",
    "    \n",
    "    # 创建一个常量张量\n",
    "    # tf_valid_dataset = Tensor(\"Const:0\", shape=(10000, 784), dtype=float32)\n",
    "    tf_valid_dataset = tf.constant(validation_images)\n",
    "    tf_test_dataset = tf.constant(test_images)\n",
    "    \n",
    "    # 转换数据类型\n",
    "    tf_valid_dataset = tf.to_float(tf_valid_dataset)\n",
    "    tf_test_dataset = tf.to_float(tf_test_dataset)\n",
    "    # ------------------------------------------2\n",
    "    # 变量\n",
    "    # #该函数返回以下结果\n",
    "    # decayed_learning_rate = learning_rate *\n",
    "    # decay_rate ^ (global_step / decay_steps)\n",
    "    # 初始的学习速率\n",
    "    starter_learning_rate = 0.1\n",
    "    # 全局的step，与 decay_step 和 decay_rate一起决定了 learning rate的变化\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    # 衰减速度\n",
    "    decay_steps = 100\n",
    "    # 衰减系数\n",
    "    decay_rate = 0.7\n",
    "    # 如果staircase=True，那就表明每decay_steps次计算学习速率变化，更新原始学习速率.\n",
    "    # 如果是False，那就是每一步都更新学习速率\n",
    "    staircase = True\n",
    "    # 指数衰减:法通过这个函数，可以先使用较大的学习率来快速得到一个比较优的解，然后随着迭代的继续逐步减小学习率，使得模型在训练后期更加稳定\n",
    "    # 87.7% 仅仅指数衰减\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate,global_step,decay_steps,decay_rate,staircase)\n",
    "    \n",
    "    # 当你训练一个模型的时候，你使用变量去保存和更新参数。\n",
    "    # 在Tensorflow中变量是内存缓冲区中保存的张量（tensor）。\n",
    "\n",
    "    # 第一层\n",
    "    # truncated_normal 从一个正态分布片段中输出随机数值,\n",
    "    # 生成的值会遵循一个指定了平均值和标准差的正态分布，只保留两个标准差以内的值，超出的值会被弃掉重新生成。\n",
    "    # 返回 一个指定形状并用正态分布片段的随机值填充的张量\n",
    "    # 数字平方根\n",
    "    x = 2.0\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size, hidden_nodes], stddev = np.sqrt(x / hidden_nodes)))\n",
    "    biases1 = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    \n",
    "    # 第二层\n",
    "    weights2 = tf.Variable(tf.truncated_normal([hidden_nodes, int(hidden_nodes / 2)], stddev = np.sqrt(x / hidden_nodes / 2)))\n",
    "    biases2 = tf.Variable(tf.zeros([hidden_nodes / 2]))\n",
    "    hidden_nodes = int(hidden_nodes / 2)\n",
    "    \n",
    "    # 第三层\n",
    "    weights3 = tf.Variable(tf.truncated_normal([hidden_nodes, int(hidden_nodes / 2)], stddev = np.sqrt(x / hidden_nodes / 2)))\n",
    "    biases3 = tf.Variable(tf.zeros([hidden_nodes / 2]))\n",
    "    hidden_nodes = int(hidden_nodes / 2)\n",
    "    \n",
    "    # 第四层 94.5\n",
    "    weights4 = tf.Variable(tf.truncated_normal([hidden_nodes, int(hidden_nodes / 2)], stddev = np.sqrt(x / hidden_nodes / 2)))\n",
    "    biases4 = tf.Variable(tf.zeros([hidden_nodes / 2]))\n",
    "    hidden_nodes = int(hidden_nodes / 2)\n",
    "    \n",
    "    # 第五层 94.5\n",
    "    weights5 = tf.Variable(tf.truncated_normal([hidden_nodes, int(hidden_nodes / 2)], stddev = np.sqrt(x / hidden_nodes / 2)))\n",
    "    biases5 = tf.Variable(tf.zeros([hidden_nodes / 2]))\n",
    "    hidden_nodes = int(hidden_nodes / 2)\n",
    "    \n",
    "    # 最后一层\n",
    "    weights_end = tf.Variable(tf.truncated_normal([hidden_nodes, labels_count], stddev = np.sqrt(x / labels_count)))\n",
    "    biases_end  = tf.Variable(tf.zeros([labels_count]))\n",
    "    \n",
    "    # -------------------------------------------3\n",
    "    # 训练计算.\n",
    "    # logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    # DropDown的保留概率\n",
    "    keep_prob = 0.8\n",
    "    drop = tf.nn.dropout(tf_train_dataset, keep_prob=keep_prob)\n",
    "    \n",
    "    train_logits = compute_logits(tf_train_dataset, [weights1, weights2, weights3,weights4,weights5, weights_end], \n",
    "                                  [biases1,biases2,biases3,biases4,biases5, biases_end],  \n",
    "                            dropout_vals=(1.0,0.95,0.95,0.95,0.95,1.0))\n",
    "    \n",
    "    # train_logits = tf.add(tf.matmul(drop, weights1),biases1)\n",
    "    # train_logits = tf.nn.relu(train_logits)\n",
    "    # train_logits = tf.add(tf.matmul(train_logits,weights2),biases2)\n",
    "\n",
    "    valid_logits = compute_logits(tf_valid_dataset, [weights1, weights2, weights3,weights4,weights5, weights_end], \n",
    "                              [biases1,biases2,biases3,biases4,biases5, biases_end])\n",
    "    \n",
    "    # valid_logits = tf.add(tf.matmul(tf_valid_dataset, weights1),biases1)\n",
    "    # valid_logits = tf.nn.relu(valid_logits)\n",
    "    # valid_logits = tf.add(tf.matmul(valid_logits,weights2),biases2)\n",
    "\n",
    "    test_logits = compute_logits(tf_test_dataset, [weights1, weights2, weights3,weights4,weights5, weights_end], \n",
    "                              [biases1,biases2,biases3,biases4,biases5, biases_end])\n",
    "    \n",
    "    # test_logits = tf.add(tf.matmul(tf_test_dataset, weights1),biases1)\n",
    "    # test_logits = tf.nn.relu(test_logits)\n",
    "    # test_logits = tf.add(tf.matmul(test_logits,weights2),biases2)\n",
    "    \n",
    "    # reduce_mean可跨越维度的计算张量各元素的平均值\n",
    "    # 计算loss是代价值，也就是我们要最小化的值\n",
    "    # 第一个参数logits：就是神经网络最后一层的输出，\n",
    "    # 如果有batch的话，它的大小就是[batchsize，num_classes]，单样本的话，大小就是num_classes\n",
    "    # 第二个参数labels：实际的标签，大小同上\n",
    "    # 第一步是先对网络最后一层的输出做一个softmax，这一步通常是求取输出属于某一类的概率\n",
    "    # 第二步是softmax的输出向量[Y1，Y2,Y3...]和样本的实际标签做一个交叉熵\n",
    "    # 注意！！！这个函数的返回值并不是一个数，而是一个向量.\n",
    "    # 如果要求交叉熵，我们要再做一步tf.reduce_sum操作,就是对向量里面所有元素求和，最后才得到. \n",
    "    # 如果求loss，则要做一步tf.reduce_mean操作，对向量求均值！\n",
    "    \n",
    "    # 如果直接将l2_loss加到train_loss上，每次的train_loss都特别大，几乎只取决于l2_loss\n",
    "    # 为了让原本的train_loss与l2_loss都能较好地对参数调整方向起作用，它们应当至少在同一个量级\n",
    "    # 这里还有一个重要的点，Hyper Parameter: β\n",
    "    # 我觉得这是一个拍脑袋参数，取什么值都行，但效果会不同，我这里解释一下我取β=0.001的理由\n",
    "    # 为了让原本的train_loss与l2_loss都能较好地对参数调整方向起作用，它们应当至少在同一个量级\n",
    "    # 观察不加l2_loss，step 0 时，train_loss在300左右\n",
    "    # 加l2_loss后， step 0 时，train_loss在300000左右\n",
    "    # 因此给l2_loss乘0.0001使之降到同一个量级\n",
    "    # 原始 loss=18\n",
    "    # loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=train_logits, labels=tf_train_labels))\n",
    "    # 原始L2后loss=58000\n",
    "    #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=train_logits)) * tf.nn.l2_loss(weights)  \n",
    "    # 使用Hyper Parameter 0.0001 相乘来降低L2的影响，使用后loss=16\n",
    "    #hpl2 = regularation_param * tf.nn.l2_loss(weights)\n",
    "    #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=train_logits))\n",
    "    #loss = tf.add(loss, hpl2)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=train_logits)) + regularation_param * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))  \n",
    "\n",
    "    \n",
    "    #loss = tf.add(loss,\n",
    "    # -------------------------------------------4\n",
    "    # 最优化.因为深度学习常见的是对于梯度的优化，也就是说，优化器最后其实就是各种对于梯度下降算法的优化。 \n",
    "    # 函数training()通过梯度下降法为最小化损失函数增加了相关的优化操作，在训练过程中，\n",
    "    # 先实例化一个优化函数，比如 tf.train.GradientDescentOptimizer，并基于一定的学习率进行梯度优化训练：\n",
    "    # learning_rate参数：要使用的学习率 \n",
    "    # minimize：非常常用的一个函数 通过更新var_list来减小loss，这个函数就是前面compute_gradients() 和apply_gradients().的结合\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    \n",
    "    #--------------------------------------------5\n",
    "    # 预测训练, 验证,和测试数据.\n",
    "    # tf.nn.softmax仅产生将softmax function应用于输入张量的结果。 \n",
    "    # softmax 压扁输入，使sum(输入)= 1;这是一种正常化的方式。 \n",
    "    # softmax的输出形状与输入相同 – 它只是对值进行归一化。 \n",
    "    # softmax的输出可以解释为概率。\n",
    "    # a = tf.constant(np.array([[.1, .3, .5, .9]]))\n",
    "    # print s.run(tf.nn.softmax(a))\n",
    "    # [[ 0.16838508  0.205666    0.25120102  0.37474789]]\n",
    "    print(train_logits.get_shape())\n",
    "    train_prediction = tf.nn.softmax(train_logits)\n",
    "    valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    test_prediction = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.403658\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 25.1%\n",
      "Minibatch loss at step 500: 0.239031\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 95.2%\n",
      "Minibatch loss at step 1000: 0.165987\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 95.8%\n",
      "Minibatch loss at step 1500: 0.191577\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 96.0%\n",
      "Minibatch loss at step 2000: 0.260533\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 96.0%\n",
      "Minibatch loss at step 2500: 0.185398\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 96.0%\n",
      "Minibatch loss at step 3000: 0.231877\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 96.1%\n",
      "Minibatch loss at step 3500: 0.227199\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 96.1%\n",
      "Minibatch loss at step 4000: 0.278643\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 96.1%\n",
      "Minibatch loss at step 4500: 0.255103\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 96.1%\n",
      "Minibatch loss at step 5000: 0.162693\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 96.1%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 5001  \n",
    "  \n",
    "with tf.Session(graph=graph) as session:  \n",
    "    tf.global_variables_initializer().run()  \n",
    "    print(\"Initialized\")  \n",
    "    for step in range(num_steps):  \n",
    "        # 在训练数据中选择一个已被随机化的偏移量.\n",
    "        # 提醒: 我们能使用更好的随机化穿过所有数据.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)  \n",
    "        # 生成一个小批量数据\n",
    "        batch_data = train_images[offset:(offset + batch_size), :]  \n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]  \n",
    "        # feed_dict的作用是给使用placeholder创建出来的tensor赋值。\n",
    "        # 其实，他的作用更加广泛：feed 使用一个 值临时替换一个 op 的输出结果. \n",
    "        # 你可以提供 feed 数据作为 run() 调用的参数. feed 只在调用它的方法内有效, 方法结束, feed 就会消失.\n",
    "        #  传递值到tf的命名空间  \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}  \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)  \n",
    "        if (step % 500 == 0):  \n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))  \n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))  \n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), validation_labels))  \n",
    "    # 获取结果，用于保存\n",
    "    test_prediction_np = test_prediction.eval()\n",
    "    test_prediction_np = np.argmax(test_prediction_np, 1)\n",
    "    savecsv(test_prediction_np)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 (29400, 784) (29400, 10)\n",
      "验证集 (12600, 784) (12600, 10)\n",
      "测试集 (28000, 784)\n",
      "训练集 (29400, 28, 28, 1) (29400, 10)\n",
      "验证集 (12600, 28, 28, 1) (12600, 10)\n",
      "测试集 (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "print('训练集', train_images.shape, train_labels.shape)\n",
    "print('验证集', validation_images.shape, validation_labels.shape)\n",
    "print('测试集', test_images.shape)\n",
    "valid_labels = validation_labels\n",
    "def reformat2(dataset, labels):\n",
    "    dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "def reformat1(dataset):\n",
    "    dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "    return dataset\n",
    "train_dataset = reformat1(train_images)\n",
    "valid_dataset = reformat1(validation_images)\n",
    "test_dataset = reformat1(test_images)\n",
    "print('训练集', train_dataset.shape, train_labels.shape)\n",
    "print('验证集', valid_dataset.shape, valid_labels.shape)\n",
    "print('测试集', test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv模型\n",
    "def model_conv(data):\n",
    "    # tf.nn.conv2d是TensorFlow里面实现卷积的函数\n",
    "    # tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)\n",
    "    # 第一个参数input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，\n",
    "    # 具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，注意这是一个4维的Tensor，要求类型为float32和float64其中之一\n",
    "    # 第二个参数filter：相当于CNN中的卷积核，二维的滤波器矩阵，也叫权重矩阵\n",
    "    # 它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，\n",
    "    # 具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，\n",
    "    # 有一个地方需要注意，第三维in_channels，就是参数input的第四维\n",
    "    # 最后的out_channels是输出几个图的结果（深度）\n",
    "    # 第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
    "    # strides[0]和strides[3]的两个1是默认值，中间两个1代表padding时在x方向运动一步，y方向运动一步\n",
    "    # 第一个是批处理（batch），最后一个是卷积的深度（depth）\n",
    "    # 第四个参数padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式\n",
    "    # V是不可超越边界是图片尺寸-核尺寸+1/步长，S是可以超越的，核心位置可以贴变，特征结果是图片尺寸／步长\n",
    "    # 第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true\n",
    "    # 输出结果[0]是批处理（batch）[1]和[2]是图片经过过滤器后的长宽结果，[3]是卷积的深度（depth）\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print(shape)\n",
    "    \n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print(shape)\n",
    "    \n",
    "    conv = tf.nn.conv2d(hidden, layer21_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer21_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print(shape)\n",
    "    \n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    print(\"hidden.shape\", shape[0] , shape[1] , shape[2] , shape[3])\n",
    "    print(\"reshape.shape\", reshape.shape)\n",
    "    print(\"layer3_weights.shape\", layer3_weights.shape)\n",
    "    \n",
    "    hidden = tf.matmul(reshape, layer3_weights)\n",
    "    hidden = tf.nn.relu(hidden + layer3_biases)\n",
    "    \n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maxpool模型\n",
    "# 1.1增加深度到32和每一层卷积都增加池化后，卷积步进1，池化步进2，提高到0.98229\n",
    "# num_hidden从128增加到1024 \n",
    "def model_maxpool(data):\n",
    "    # tf.nn.conv2d是TensorFlow里面实现卷积的函数\n",
    "    # tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)\n",
    "    # 第一个参数input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，\n",
    "    #                具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，\n",
    "    #                注意这是一个4维的Tensor，要求类型为float32和float64其中之一\n",
    "    # 第二个参数filter：相当于CNN中的卷积核，二维的滤波器矩阵，也叫权重矩阵\n",
    "    #                 要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，\n",
    "    #                 具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，\n",
    "    #                 有一个地方需要注意，第三维in_channels，就是参数input的第四维\n",
    "    #                 最后的out_channels是输出几个图的结果（深度）\n",
    "    # 第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
    "    #                  strides[0]和strides[3]的两个1是默认值，中间两个1代表padding时在x方向运动一步，y方向运动一步\n",
    "    #                  第一个是批处理（batch），最后一个是卷积的深度（depth）\n",
    "    # 第四个参数padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式\n",
    "    #                  V是不可超越边界是图片尺寸-核尺寸+1/步长，S是可以超越的，核心位置可以贴变，特征结果是图片尺寸／步长\n",
    "    # 第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true\n",
    "    #           输出结果[0]是批处理（batch）[1]和[2]是图片经过过滤器后的长宽结果，[3]是卷积的深度（depth）\n",
    "    \n",
    "    # 池化操作max_pool 参数：\n",
    "    # value：需要池化的输入。\n",
    "    #       一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch, height, width, channels]这样的shape.\n",
    "    # ksize：池化窗口的大小。\n",
    "    #       取一个四维向量，一般是[1, height, width, 1]，因为我们不想在batch和channels上做池化，所以这两个维度设为了1.\n",
    "    # strides：和卷积类似，窗口在每一个维度上滑动的步长，一般也是[1, stride,stride, 1]\n",
    "    # padding：和卷积类似，可以取'VALID' 或者'SAME'\n",
    "    # data_format：字符串. 目前支持 'NHWC' 和 'NCHW'.\n",
    "    \n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    conv = tf.nn.max_pool(conv, [1,2,2,1], [1,2,2,1], padding='SAME') # 池化\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "\n",
    "    \n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    conv = tf.nn.max_pool(conv, [1,2,2,1], [1,2,2,1], padding='SAME') # 池化\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "\n",
    "    \n",
    "#     conv = tf.nn.conv2d(hidden, layer21_weights, [1, 1, 1, 1], padding='SAME')\n",
    "#     conv = tf.nn.max_pool(conv, [1,2,2,1], [1,2,2,1], padding='SAME') # 池化\n",
    "#     hidden = tf.nn.relu(conv + layer21_biases)\n",
    "    \n",
    "    \n",
    "    shape = hidden.get_shape().as_list()\n",
    "\n",
    "\n",
    "#     print(\"maxpool.shape\",shape)\n",
    "#     print(\"hidden.shape\", shape[0] , shape[1] , shape[2] , shape[3])\n",
    "#     print(\"layer3_weights.shape\", layer3_weights.shape)\n",
    "    \n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "#     print(\"reshape.shape\", reshape.shape)\n",
    "    \n",
    "    # DropOut\n",
    "    keep_prob = 0.6\n",
    "    hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "patch_size = 5\n",
    "depth = 32\n",
    "num_hidden = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "regularation_param = 0.0001  \n",
    "# maxpool 1.2，1.2 + 1024   32，5，32，1024 =  0.97914\n",
    "# 加入L2  0.98143\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # 输入数据\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    \n",
    "    #转数据类型，f64->f32\n",
    "    tf_train_dataset = tf.to_float(tf_train_dataset)\n",
    "    tf_valid_dataset = tf.to_float(tf_valid_dataset)\n",
    "    tf_test_dataset = tf.to_float(tf_test_dataset)\n",
    "\n",
    "    # 变量，在这里是过滤器用\n",
    "    # truncated_normal按照正态分布初始化权重\n",
    "    # mean是正态分布的平均值\n",
    "    # stddev是正态分布的标准差（standard deviation）\n",
    "    # seed是作为分布的random seed（随机种子，我百度了一下，跟什么伪随机数发生器还有关，就是产生随机数的）\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    layer21_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "    layer21_biases = tf.Variable(tf.constant(1.0, shape=[depth ]))\n",
    "    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    # 全连接层\n",
    "    layer3_weights = tf.Variable(tf.truncated_normal([1568, num_hidden], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "#     print(\"image_size\",image_size)\n",
    "#     print(layer4_weights.shape)\n",
    "    layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "\n",
    "    # 训练计算\n",
    "    # 损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度\n",
    "    # 它是一个非负实值函数，通常使用L(Y, f(x))来表示，损失函数越小，模型的可能指就越好。\n",
    "    logits = model_maxpool(tf_train_dataset)\n",
    "    \n",
    "#     print(logits.get_shape())# (16, 10)\n",
    "#     print(tf_train_labels.get_shape()) # (16, 10)\n",
    "\n",
    "    hpl2 = regularation_param * (tf.nn.l2_loss(layer1_weights) \n",
    "                                 + tf.nn.l2_loss(layer21_weights)\n",
    "                                 + tf.nn.l2_loss(layer2_weights)\n",
    "                                 + tf.nn.l2_loss(layer3_weights)\n",
    "                                 + tf.nn.l2_loss(layer4_weights))\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    loss = tf.add(loss , hpl2)\n",
    "\n",
    "\n",
    "    # loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "    # 初始的学习速率\n",
    "    starter_learning_rate = 0.1\n",
    "    # 全局的step，与 decay_step 和 decay_rate一起决定了 learning rate的变化\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    # 衰减速度\n",
    "    decay_steps = 50\n",
    "    # 衰减系数\n",
    "    decay_rate = 0.9\n",
    "    # 如果staircase=True，那就表明每decay_steps次计算学习速率变化，更新原始学习速率.\n",
    "    # 如果是False，那就是每一步都更新学习速率\n",
    "    staircase = False\n",
    "    # 指数衰减:法通过这个函数，可以先使用较大的学习率来快速得到一个比较优的解，然后随着迭代的继续逐步减小学习率，使得模型在训练后期更加稳定\n",
    "    # 87.7% 仅仅指数衰减\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate,global_step,decay_steps,decay_rate,staircase)\n",
    "    \n",
    "    \n",
    "    # 优化器\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(0.03).minimize(loss)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.03).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    # 对训练，验证和测试数据集进行预测\n",
    "    \n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model_maxpool(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model_maxpool(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 21.089691\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.3%\n",
      "Minibatch loss at step 200: 3.893891\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 13.5%\n",
      "Minibatch loss at step 400: 1.237122\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 72.0%\n",
      "Minibatch loss at step 600: 1.104865\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 800: 1.787780\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 1000: 1.036048\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 1200: 0.821458\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 1400: 0.845929\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1500\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 200 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    # 获取结果，用于保存\n",
    "    test_prediction_np = test_prediction.eval()\n",
    "    test_prediction_np = np.argmax(test_prediction_np, 1)\n",
    "    savecsv(test_prediction_np,\"submission_uda_conv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 误差= 18.0152\n",
      "200 误差= 5.805\n",
      "400 误差= 1.28473\n",
      "600 误差= 1.19647\n",
      "800 误差= 1.1493\n",
      "1000 误差= 0.760313\n",
      "1200 误差= 0.783055\n",
      "1400 误差= 1.20815\n",
      "1600 误差= 0.78628\n",
      "1800 误差= 1.02609\n",
      "2000 误差= 0.832723\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(2001):\n",
    "        offset = (i * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        # 输出loss值\n",
    "        if i % 200 == 0: \n",
    "            print(i, '误差=',l)  \n",
    "\n",
    "    print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [Deep MNIST for Experts](https://www.tensorflow.org/versions/master/tutorials/mnist/pros/index.html#deep-mnist-for-experts)\n",
    "- [A Convolutional Network implementation example using TensorFlow library](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3%20-%20Neural%20Networks/convolutional_network.ipynb)\n",
    "- [Digit recognizer in Python using CNN](https://www.kaggle.com/kobakhit/digit-recognizer/digit-recognizer-in-python-using-cnn)\n",
    "- [Deep Learning in a Nutshell: Core Concepts](http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
